{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1379a435",
   "metadata": {},
   "source": [
    "# Return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1c404a",
   "metadata": {},
   "source": [
    "## Problem. \n",
    "The problem of return prediction is one of the current points of interest in the financial world. The aim of this project is to forecast the returns of Meta stock based on the last 7 days of price and volume data for three stocks from the same industry – Amazon, Intel and Meta itself. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c9a6d5",
   "metadata": {},
   "source": [
    "## Model and Data.\n",
    "One of the most widely used models for forecasting of time series data is Long-Short-Term-Memory model. It is a recurring neural network model, that can store information over some period of time. This feature allows the model to account for patterns in time series data, which makes it a good model for returns predictions. In order to work with LSTM, tensorflow and keras libraries in Python are used. Tensorflow will be used for creating generators when working with time series data, while keras will help to build NN models.\n",
    "The data for this study is taken from Nasdaq website and includes 5 years of daily stock prices and volumes for three chosen assets. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8926801b",
   "metadata": {},
   "source": [
    "## Step 1. Downloading libraries and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7b34f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "# import keras\n",
    "from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7951ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "amzn = pd.read_csv('data/hd_amzn.csv')   \n",
    "intc = pd.read_csv('data/hd_intc.csv')   \n",
    "meta = pd.read_csv('data/hd_meta.csv')  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0ca4da",
   "metadata": {},
   "source": [
    "## Step 2. Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b56dbe",
   "metadata": {},
   "source": [
    "Inspect the data and check for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "887ec3df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date Close/Last     Volume     Open       High      Low\n",
      "0  09/25/2024    $192.53   26391140  $193.75  $193.9498  $192.16\n",
      "1  09/24/2024    $193.96   43478930  $194.27    $195.37  $190.13\n",
      "2  09/23/2024    $193.88   36993110  $191.64    $194.45  $190.57\n",
      "3  09/20/2024    $191.60  100378600  $190.23    $191.84  $187.41\n",
      "4  09/19/2024    $189.87   39543170  $190.04    $190.99  $188.47\n",
      "         Date Close/Last     Volume    Open     High      Low\n",
      "0  09/25/2024     $23.54  117013400  $22.80  $24.055   $22.73\n",
      "1  09/24/2024     $22.81  113082500  $22.53  $23.105  $22.285\n",
      "2  09/23/2024     $22.56  184439100  $22.43   $22.82   $22.03\n",
      "3  09/20/2024     $21.84  260377900  $20.89   $23.14   $20.35\n",
      "4  09/19/2024     $21.14   99829170  $21.28   $21.69   $21.03\n",
      "         Date Close/Last    Volume     Open       High        Low\n",
      "0  09/25/2024    $568.31  16543350  $564.05    $576.88    $563.72\n",
      "1  09/24/2024    $563.33  12992960  $566.68   $567.745    $554.19\n",
      "2  09/23/2024    $564.41  12830670  $569.50  $573.9799    $562.41\n",
      "3  09/20/2024    $561.35  22066820  $560.00    $564.50  $556.3001\n",
      "4  09/19/2024    $559.10  15646950  $550.00    $562.07    $546.52\n"
     ]
    }
   ],
   "source": [
    "print(amzn.head())\n",
    "print(intc.head())\n",
    "print(meta.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48cc25bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date          0\n",
      "Close/Last    0\n",
      "Volume        0\n",
      "Open          0\n",
      "High          0\n",
      "Low           0\n",
      "dtype: int64\n",
      "Date          0\n",
      "Close/Last    0\n",
      "Volume        0\n",
      "Open          0\n",
      "High          0\n",
      "Low           0\n",
      "dtype: int64\n",
      "Date          0\n",
      "Close/Last    0\n",
      "Volume        0\n",
      "Open          0\n",
      "High          0\n",
      "Low           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(amzn.isnull().sum())\n",
    "print(intc.isnull().sum())\n",
    "print(meta.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47a5e54e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Study\\prjcts\\bd\\return_prediction\\prep_data.py:15: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will*not* be treated as literal strings when regex=True.\n",
      "  df[\"Close/Last\"] = df[\"Close/Last\"].astype(str).str.replace('$', '')\n"
     ]
    }
   ],
   "source": [
    "from prep_data import clean_data\n",
    "\n",
    "amzn_cl = clean_data(amzn)\n",
    "intc_cl = clean_data(intc)\n",
    "meta_cl = clean_data(meta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96418b53",
   "metadata": {},
   "source": [
    "## Step 3. Data preparation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d11c338",
   "metadata": {},
   "source": [
    "Calculate returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "907fbb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prep_data import generate_return\n",
    "\n",
    "amzn_cl[\"Return\"] = generate_return(amzn_cl)\n",
    "intc_cl[\"Return\"] = generate_return(intc_cl)\n",
    "meta_cl[\"Return\"] = generate_return(meta_cl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22abcf8e",
   "metadata": {},
   "source": [
    "Drop the first row that has NaN value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27331515",
   "metadata": {},
   "outputs": [],
   "source": [
    "amzn_cl = amzn_cl.dropna()\n",
    "intc_cl = intc_cl.dropna()\n",
    "meta_cl = meta_cl.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c55fb9",
   "metadata": {},
   "source": [
    "Create forecasting variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c1b7de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in meta_cl[\"Return\"]:\n",
    "   meta_cl['label'] = np.where(meta_cl[\"Return\"] > 0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c5ec079",
   "metadata": {},
   "outputs": [],
   "source": [
    "amzn_cl = amzn_cl.rename({\"Price\": \"amzn_price\", \"Volume\": \"amzn_volume\", \"Return\": \"amzn_return\"}, axis=1)\n",
    "intc_cl = intc_cl.rename({\"Price\": \"intc_price\", \"Volume\": \"intc_volume\", \"Return\": \"intc_return\"}, axis=1)\n",
    "meta_cl = meta_cl.rename({\"Price\": \"meta_price\", \"Volume\": \"meta_volume\", \"Return\": \"meta_return\"}, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06501d2",
   "metadata": {},
   "source": [
    "Combining data into one dataframe, dropping duplicating \"Date\" columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5dde1905",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([amzn_cl, intc_cl, meta_cl], axis=1)\n",
    "data = data.T.drop_duplicates().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e786c1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>amzn_price</th>\n",
       "      <th>amzn_volume</th>\n",
       "      <th>amzn_return</th>\n",
       "      <th>intc_price</th>\n",
       "      <th>intc_volume</th>\n",
       "      <th>intc_return</th>\n",
       "      <th>meta_price</th>\n",
       "      <th>meta_volume</th>\n",
       "      <th>meta_return</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>09/24/2024</td>\n",
       "      <td>193.96</td>\n",
       "      <td>43478930</td>\n",
       "      <td>0.007427</td>\n",
       "      <td>22.81</td>\n",
       "      <td>113082500</td>\n",
       "      <td>-0.031011</td>\n",
       "      <td>563.33</td>\n",
       "      <td>12992960</td>\n",
       "      <td>-0.008763</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>09/23/2024</td>\n",
       "      <td>193.88</td>\n",
       "      <td>36993110</td>\n",
       "      <td>-0.000412</td>\n",
       "      <td>22.56</td>\n",
       "      <td>184439100</td>\n",
       "      <td>-0.01096</td>\n",
       "      <td>564.41</td>\n",
       "      <td>12830670</td>\n",
       "      <td>0.001917</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>09/20/2024</td>\n",
       "      <td>191.6</td>\n",
       "      <td>100378600</td>\n",
       "      <td>-0.01176</td>\n",
       "      <td>21.84</td>\n",
       "      <td>260377900</td>\n",
       "      <td>-0.031915</td>\n",
       "      <td>561.35</td>\n",
       "      <td>22066820</td>\n",
       "      <td>-0.005422</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>09/19/2024</td>\n",
       "      <td>189.87</td>\n",
       "      <td>39543170</td>\n",
       "      <td>-0.009029</td>\n",
       "      <td>21.14</td>\n",
       "      <td>99829170</td>\n",
       "      <td>-0.032051</td>\n",
       "      <td>559.1</td>\n",
       "      <td>15646950</td>\n",
       "      <td>-0.004008</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>09/18/2024</td>\n",
       "      <td>186.43</td>\n",
       "      <td>34448130</td>\n",
       "      <td>-0.018118</td>\n",
       "      <td>20.77</td>\n",
       "      <td>118727900</td>\n",
       "      <td>-0.017502</td>\n",
       "      <td>537.95</td>\n",
       "      <td>10323540</td>\n",
       "      <td>-0.037829</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date amzn_price amzn_volume amzn_return intc_price intc_volume  \\\n",
       "1  09/24/2024     193.96    43478930    0.007427      22.81   113082500   \n",
       "2  09/23/2024     193.88    36993110   -0.000412      22.56   184439100   \n",
       "3  09/20/2024      191.6   100378600    -0.01176      21.84   260377900   \n",
       "4  09/19/2024     189.87    39543170   -0.009029      21.14    99829170   \n",
       "5  09/18/2024     186.43    34448130   -0.018118      20.77   118727900   \n",
       "\n",
       "  intc_return meta_price meta_volume meta_return label  \n",
       "1   -0.031011     563.33    12992960   -0.008763     0  \n",
       "2    -0.01096     564.41    12830670    0.001917     1  \n",
       "3   -0.031915     561.35    22066820   -0.005422     0  \n",
       "4   -0.032051      559.1    15646950   -0.004008     0  \n",
       "5   -0.017502     537.95    10323540   -0.037829     0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8453751",
   "metadata": {},
   "source": [
    "Split data into test, train and validation sets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d398483a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_val, data_test = train_test_split(data, test_size=0.20, shuffle=False)\n",
    "data_train, data_val = train_test_split(data_train_val, test_size=0.25, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19dd614e",
   "metadata": {},
   "source": [
    "Standardising returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0b54a838",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prep_data import standardise_return\n",
    "\n",
    "data_test['std_return_amzn'] = standardise_return(data_test[\"amzn_return\"])\n",
    "data_test['std_return_intc'] = standardise_return(data_test[\"intc_return\"])\n",
    "data_test['std_return_meta'] = standardise_return(data_test[\"meta_return\"])\n",
    "\n",
    "data_train['std_return_amzn'] = standardise_return(data_train[\"amzn_return\"])\n",
    "data_train['std_return_intc'] = standardise_return(data_train[\"intc_return\"])\n",
    "data_train['std_return_meta'] = standardise_return(data_train[\"meta_return\"])\n",
    "\n",
    "data_val['std_return_amzn'] = standardise_return(data_val[\"amzn_return\"])\n",
    "data_val['std_return_intc'] = standardise_return(data_val[\"intc_return\"])\n",
    "data_val['std_return_meta'] = standardise_return(data_val[\"meta_return\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1478c9",
   "metadata": {},
   "source": [
    "Standardising volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "18275151",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prep_data import standardise_volume\n",
    "\n",
    "data_test['std_volume_amzn'] = standardise_volume(data_test[\"amzn_volume\"])\n",
    "data_test['std_volume_intc'] = standardise_volume(data_test[\"intc_volume\"])\n",
    "data_test['std_volume_meta'] = standardise_volume(data_test[\"meta_volume\"])\n",
    "\n",
    "data_train['std_volume_amzn'] = standardise_volume(data_train[\"amzn_volume\"])\n",
    "data_train['std_volume_intc'] = standardise_volume(data_train[\"intc_volume\"])\n",
    "data_train['std_volume_meta'] = standardise_volume(data_train[\"meta_volume\"])\n",
    "\n",
    "data_val['std_volume_amzn'] = standardise_volume(data_val[\"amzn_volume\"])\n",
    "data_val['std_volume_intc'] = standardise_volume(data_val[\"intc_volume\"])\n",
    "data_val['std_volume_meta'] = standardise_volume(data_val[\"meta_volume\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9cdc4918",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = data_train.dropna()\n",
    "data_val = data_val.dropna()\n",
    "data_test = data_test.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "28fc8ac6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date               object\n",
       "amzn_price         object\n",
       "amzn_volume        object\n",
       "amzn_return        object\n",
       "intc_price         object\n",
       "intc_volume        object\n",
       "intc_return        object\n",
       "meta_price         object\n",
       "meta_volume        object\n",
       "meta_return        object\n",
       "label              object\n",
       "std_return_amzn    object\n",
       "std_return_intc    object\n",
       "std_return_meta    object\n",
       "std_volume_amzn    object\n",
       "std_volume_intc    object\n",
       "std_volume_meta    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7172efe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_dict = {'std_volume_amzn': float, 'std_volume_intc': float, 'std_volume_meta': float, \n",
    "                'std_return_amzn': float, 'std_return_intc': float, 'std_return_meta': float\n",
    "                }\n",
    "data_train = data_train.astype(convert_dict)\n",
    "data_val = data_val.astype(convert_dict)\n",
    "data_test = data_test.astype(convert_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2abcddb4",
   "metadata": {},
   "source": [
    "## Step 4. Model architecture and testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27038fef",
   "metadata": {},
   "source": [
    "Creating training, validation, and testing generators.\n",
    "Setting an input as standardised returns and standardised volume for all three stocks; setting the output as the label variable for Meta.\n",
    "Length - 7 days, as per problem description.\n",
    "Batch size - 32."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "156a4d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = TimeseriesGenerator(\n",
    "    data_train[\n",
    "        ['std_return_amzn', 'std_volume_amzn', 'std_return_intc', 'std_volume_intc', 'std_return_meta', 'std_volume_meta']\n",
    "    ].values, data_train['label'].values, length=7, batch_size=32)\n",
    "val_generator = TimeseriesGenerator(\n",
    "    data_val[\n",
    "        ['std_return_amzn', 'std_volume_amzn', 'std_return_intc', 'std_volume_intc', 'std_return_meta', 'std_volume_meta']\n",
    "    ].values, data_val['label'].values, length=7, batch_size=32)\n",
    "test_generator = TimeseriesGenerator(\n",
    "    data_test[\n",
    "        ['std_return_amzn', 'std_volume_amzn', 'std_return_intc', 'std_volume_intc', 'std_return_meta', 'std_volume_meta']\n",
    "    ].values, data_test['label'].values, length=7, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dccb958",
   "metadata": {},
   "source": [
    "Creating a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "56b7cd23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import model_fn\n",
    "from model import random_search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "989a086c",
   "metadata": {},
   "source": [
    "Using cross validation to choose the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "066b8034",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = {'lstm_size': np.linspace(10, 150, 5, dtype=int),\n",
    "                'dropout': np.linspace(0, 0.6, 5),\n",
    "                'learning_rate': np.linspace(0.0001, 0.01, 5)}\n",
    "iterations = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7d632fce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-68-024afe822ad6>:9: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history = model.fit_generator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 4s 47ms/step - loss: 0.7030 - accuracy: 0.4677 - val_loss: 0.6940 - val_accuracy: 0.5204\n",
      "Epoch 2/100\n",
      "22/22 [==============================] - 0s 19ms/step - loss: 0.6901 - accuracy: 0.5567 - val_loss: 0.6928 - val_accuracy: 0.5102\n",
      "Epoch 3/100\n",
      "22/22 [==============================] - 0s 19ms/step - loss: 0.6833 - accuracy: 0.5581 - val_loss: 0.6915 - val_accuracy: 0.5357\n",
      "Epoch 4/100\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 0.6811 - accuracy: 0.5839 - val_loss: 0.6923 - val_accuracy: 0.5153\n",
      "Epoch 5/100\n",
      "22/22 [==============================] - 0s 17ms/step - loss: 0.6776 - accuracy: 0.5725 - val_loss: 0.6884 - val_accuracy: 0.5714\n",
      "Epoch 6/100\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 0.6789 - accuracy: 0.5710 - val_loss: 0.6957 - val_accuracy: 0.5102\n",
      "Epoch 7/100\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 0.6676 - accuracy: 0.5911 - val_loss: 0.6952 - val_accuracy: 0.5357\n",
      "Epoch 8/100\n",
      "22/22 [==============================] - 0s 16ms/step - loss: 0.6634 - accuracy: 0.5968 - val_loss: 0.7117 - val_accuracy: 0.5459\n",
      "Epoch 9/100\n",
      "22/22 [==============================] - 0s 19ms/step - loss: 0.6553 - accuracy: 0.6055 - val_loss: 0.6990 - val_accuracy: 0.5663\n",
      "Epoch 10/100\n",
      "22/22 [==============================] - 0s 22ms/step - loss: 0.6544 - accuracy: 0.6011 - val_loss: 0.7088 - val_accuracy: 0.5153\n",
      "Epoch 11/100\n",
      "22/22 [==============================] - 0s 17ms/step - loss: 0.6403 - accuracy: 0.6141 - val_loss: 0.7394 - val_accuracy: 0.5357\n",
      "Epoch 12/100\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 0.6329 - accuracy: 0.6184 - val_loss: 0.7909 - val_accuracy: 0.5153\n",
      "Epoch 13/100\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 0.6401 - accuracy: 0.6169 - val_loss: 0.7276 - val_accuracy: 0.5204\n",
      "Epoch 14/100\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 0.6287 - accuracy: 0.6126 - val_loss: 0.7389 - val_accuracy: 0.5357\n",
      "Epoch 15/100\n",
      "22/22 [==============================] - 0s 20ms/step - loss: 0.6215 - accuracy: 0.6370 - val_loss: 0.7182 - val_accuracy: 0.5612\n",
      "Epoch 1/100\n",
      "22/22 [==============================] - 3s 38ms/step - loss: 0.7046 - accuracy: 0.5065 - val_loss: 0.7167 - val_accuracy: 0.5000\n",
      "Epoch 2/100\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.7081 - accuracy: 0.4950 - val_loss: 0.7162 - val_accuracy: 0.5000\n",
      "Epoch 3/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.7077 - accuracy: 0.5007 - val_loss: 0.7155 - val_accuracy: 0.4949\n",
      "Epoch 4/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.7071 - accuracy: 0.4849 - val_loss: 0.7150 - val_accuracy: 0.5000\n",
      "Epoch 5/100\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.7076 - accuracy: 0.4835 - val_loss: 0.7144 - val_accuracy: 0.4949\n",
      "Epoch 6/100\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.7044 - accuracy: 0.4935 - val_loss: 0.7139 - val_accuracy: 0.4847\n",
      "Epoch 7/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.7075 - accuracy: 0.4864 - val_loss: 0.7133 - val_accuracy: 0.4847\n",
      "Epoch 8/100\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.7032 - accuracy: 0.4935 - val_loss: 0.7128 - val_accuracy: 0.4847\n",
      "Epoch 9/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.7062 - accuracy: 0.4993 - val_loss: 0.7123 - val_accuracy: 0.4847\n",
      "Epoch 10/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.7011 - accuracy: 0.4978 - val_loss: 0.7118 - val_accuracy: 0.4949\n",
      "Epoch 11/100\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.7038 - accuracy: 0.4935 - val_loss: 0.7114 - val_accuracy: 0.4847\n",
      "Epoch 1/100\n",
      "22/22 [==============================] - 4s 59ms/step - loss: 0.7072 - accuracy: 0.5007 - val_loss: 0.6880 - val_accuracy: 0.5357\n",
      "Epoch 2/100\n",
      "22/22 [==============================] - 1s 27ms/step - loss: 0.6899 - accuracy: 0.5308 - val_loss: 0.6936 - val_accuracy: 0.4847\n",
      "Epoch 3/100\n",
      "22/22 [==============================] - 1s 28ms/step - loss: 0.6863 - accuracy: 0.5610 - val_loss: 0.6839 - val_accuracy: 0.5357\n",
      "Epoch 4/100\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 0.6835 - accuracy: 0.5452 - val_loss: 0.6880 - val_accuracy: 0.5204\n",
      "Epoch 5/100\n",
      "22/22 [==============================] - 1s 27ms/step - loss: 0.6696 - accuracy: 0.5925 - val_loss: 0.6913 - val_accuracy: 0.5051\n",
      "Epoch 6/100\n",
      "22/22 [==============================] - 1s 27ms/step - loss: 0.6557 - accuracy: 0.5968 - val_loss: 0.6889 - val_accuracy: 0.5612\n",
      "Epoch 7/100\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 0.6431 - accuracy: 0.6227 - val_loss: 0.7332 - val_accuracy: 0.5204\n",
      "Epoch 8/100\n",
      "22/22 [==============================] - 1s 28ms/step - loss: 0.6273 - accuracy: 0.6327 - val_loss: 0.7375 - val_accuracy: 0.5408\n",
      "Epoch 9/100\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 0.5770 - accuracy: 0.6829 - val_loss: 0.7659 - val_accuracy: 0.5357\n",
      "Epoch 10/100\n",
      "22/22 [==============================] - 1s 28ms/step - loss: 0.5469 - accuracy: 0.7145 - val_loss: 0.8382 - val_accuracy: 0.5459\n",
      "Epoch 11/100\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 0.4844 - accuracy: 0.7561 - val_loss: 0.9565 - val_accuracy: 0.5408\n",
      "Epoch 12/100\n",
      "22/22 [==============================] - 1s 26ms/step - loss: 0.4624 - accuracy: 0.7676 - val_loss: 0.9195 - val_accuracy: 0.5459\n",
      "Epoch 13/100\n",
      "22/22 [==============================] - 1s 27ms/step - loss: 0.4067 - accuracy: 0.8121 - val_loss: 1.0664 - val_accuracy: 0.5408\n",
      "Epoch 14/100\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 0.3149 - accuracy: 0.8608 - val_loss: 1.1333 - val_accuracy: 0.4796\n",
      "Epoch 15/100\n",
      "22/22 [==============================] - 1s 27ms/step - loss: 0.2235 - accuracy: 0.9024 - val_loss: 1.2897 - val_accuracy: 0.5153\n",
      "Epoch 16/100\n",
      "22/22 [==============================] - 1s 26ms/step - loss: 0.1604 - accuracy: 0.9455 - val_loss: 1.3381 - val_accuracy: 0.5357\n",
      "Epoch 1/100\n",
      "22/22 [==============================] - 4s 59ms/step - loss: 0.7000 - accuracy: 0.5108 - val_loss: 0.6926 - val_accuracy: 0.5408\n",
      "Epoch 2/100\n",
      "22/22 [==============================] - 1s 28ms/step - loss: 0.6928 - accuracy: 0.5323 - val_loss: 0.7000 - val_accuracy: 0.5000\n",
      "Epoch 3/100\n",
      "22/22 [==============================] - 1s 30ms/step - loss: 0.6840 - accuracy: 0.5409 - val_loss: 0.6892 - val_accuracy: 0.5357\n",
      "Epoch 4/100\n",
      "22/22 [==============================] - 1s 27ms/step - loss: 0.6845 - accuracy: 0.5452 - val_loss: 0.6916 - val_accuracy: 0.5306\n",
      "Epoch 5/100\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 0.6728 - accuracy: 0.5811 - val_loss: 0.6980 - val_accuracy: 0.5204\n",
      "Epoch 6/100\n",
      "22/22 [==============================] - 1s 27ms/step - loss: 0.6769 - accuracy: 0.5739 - val_loss: 0.6958 - val_accuracy: 0.5051\n",
      "Epoch 7/100\n",
      "22/22 [==============================] - 1s 23ms/step - loss: 0.6646 - accuracy: 0.5940 - val_loss: 0.7077 - val_accuracy: 0.5204\n",
      "Epoch 8/100\n",
      "22/22 [==============================] - 1s 26ms/step - loss: 0.6680 - accuracy: 0.5868 - val_loss: 0.6903 - val_accuracy: 0.5102\n",
      "Epoch 9/100\n",
      "22/22 [==============================] - 1s 28ms/step - loss: 0.6620 - accuracy: 0.5911 - val_loss: 0.7045 - val_accuracy: 0.5000\n",
      "Epoch 10/100\n",
      "22/22 [==============================] - 1s 23ms/step - loss: 0.6462 - accuracy: 0.6155 - val_loss: 0.7229 - val_accuracy: 0.5714\n",
      "Epoch 11/100\n",
      "22/22 [==============================] - 1s 28ms/step - loss: 0.6271 - accuracy: 0.6169 - val_loss: 0.6998 - val_accuracy: 0.5561\n",
      "Epoch 12/100\n",
      "22/22 [==============================] - 1s 23ms/step - loss: 0.6234 - accuracy: 0.6241 - val_loss: 0.7444 - val_accuracy: 0.5306\n",
      "Epoch 13/100\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 0.6057 - accuracy: 0.6571 - val_loss: 0.7519 - val_accuracy: 0.5357\n",
      "Epoch 14/100\n",
      "22/22 [==============================] - 1s 30ms/step - loss: 0.5887 - accuracy: 0.6643 - val_loss: 0.7134 - val_accuracy: 0.5714\n",
      "Epoch 15/100\n",
      "22/22 [==============================] - 1s 27ms/step - loss: 0.5619 - accuracy: 0.7016 - val_loss: 0.7906 - val_accuracy: 0.5612\n",
      "Epoch 16/100\n",
      "22/22 [==============================] - 1s 27ms/step - loss: 0.5464 - accuracy: 0.7073 - val_loss: 0.8470 - val_accuracy: 0.5153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/100\n",
      "22/22 [==============================] - 1s 29ms/step - loss: 0.5180 - accuracy: 0.7217 - val_loss: 0.8787 - val_accuracy: 0.5255\n",
      "Epoch 18/100\n",
      "22/22 [==============================] - 1s 23ms/step - loss: 0.4763 - accuracy: 0.7618 - val_loss: 0.9603 - val_accuracy: 0.5153\n",
      "Epoch 19/100\n",
      "22/22 [==============================] - 1s 28ms/step - loss: 0.4707 - accuracy: 0.7633 - val_loss: 0.9983 - val_accuracy: 0.5306\n",
      "Epoch 20/100\n",
      "22/22 [==============================] - 1s 28ms/step - loss: 0.4401 - accuracy: 0.7791 - val_loss: 1.0041 - val_accuracy: 0.5051\n",
      "Epoch 1/100\n",
      "22/22 [==============================] - 3s 38ms/step - loss: 0.6993 - accuracy: 0.5036 - val_loss: 0.6960 - val_accuracy: 0.4745\n",
      "Epoch 2/100\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6905 - accuracy: 0.5495 - val_loss: 0.6933 - val_accuracy: 0.5153\n",
      "Epoch 3/100\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6900 - accuracy: 0.5595 - val_loss: 0.6910 - val_accuracy: 0.5357\n",
      "Epoch 4/100\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.6798 - accuracy: 0.5897 - val_loss: 0.7005 - val_accuracy: 0.4949\n",
      "Epoch 5/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.6807 - accuracy: 0.5552 - val_loss: 0.6959 - val_accuracy: 0.5408\n",
      "Epoch 6/100\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6755 - accuracy: 0.5696 - val_loss: 0.7085 - val_accuracy: 0.5102\n",
      "Epoch 7/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.6660 - accuracy: 0.6098 - val_loss: 0.7113 - val_accuracy: 0.5357\n",
      "Epoch 8/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.6659 - accuracy: 0.5911 - val_loss: 0.7096 - val_accuracy: 0.5255\n",
      "Epoch 9/100\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6654 - accuracy: 0.6083 - val_loss: 0.6978 - val_accuracy: 0.5408\n",
      "Epoch 10/100\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6476 - accuracy: 0.6141 - val_loss: 0.7123 - val_accuracy: 0.5714\n",
      "Epoch 11/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.6371 - accuracy: 0.6428 - val_loss: 0.7379 - val_accuracy: 0.5510\n",
      "Epoch 12/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.6405 - accuracy: 0.6141 - val_loss: 0.7186 - val_accuracy: 0.5612\n",
      "Epoch 13/100\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.6213 - accuracy: 0.6370 - val_loss: 0.7299 - val_accuracy: 0.5816\n",
      "Epoch 14/100\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6195 - accuracy: 0.6514 - val_loss: 0.7292 - val_accuracy: 0.5765\n",
      "Epoch 15/100\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.5927 - accuracy: 0.6772 - val_loss: 0.7703 - val_accuracy: 0.5510\n",
      "Epoch 16/100\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.5761 - accuracy: 0.6844 - val_loss: 0.7999 - val_accuracy: 0.5918\n",
      "Epoch 17/100\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.5688 - accuracy: 0.7102 - val_loss: 0.7813 - val_accuracy: 0.5612\n",
      "Epoch 18/100\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.5540 - accuracy: 0.7030 - val_loss: 0.8021 - val_accuracy: 0.5714\n",
      "Epoch 19/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.5431 - accuracy: 0.6987 - val_loss: 0.8186 - val_accuracy: 0.5357\n",
      "Epoch 20/100\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.5128 - accuracy: 0.7403 - val_loss: 0.8861 - val_accuracy: 0.5408\n",
      "Epoch 21/100\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.4828 - accuracy: 0.7676 - val_loss: 0.8767 - val_accuracy: 0.5204\n",
      "Epoch 22/100\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.4486 - accuracy: 0.7905 - val_loss: 0.9463 - val_accuracy: 0.5663\n",
      "Epoch 23/100\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.4454 - accuracy: 0.7690 - val_loss: 0.9544 - val_accuracy: 0.5459\n",
      "Epoch 24/100\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.4219 - accuracy: 0.8149 - val_loss: 1.0262 - val_accuracy: 0.5204\n",
      "Epoch 25/100\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.3665 - accuracy: 0.8307 - val_loss: 1.0923 - val_accuracy: 0.5612\n",
      "Epoch 26/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.3504 - accuracy: 0.8364 - val_loss: 1.0782 - val_accuracy: 0.5357\n",
      "iteration 5 – lstm_size:45, dropout:0.45, learning_rate:0.00505, epochs:16, loss:0.5761, accuracy:0.6844, val_loss:0.7999, val_accuracy:0.5918\n",
      "Epoch 1/100\n",
      "22/22 [==============================] - 3s 38ms/step - loss: 0.6972 - accuracy: 0.5007 - val_loss: 0.6880 - val_accuracy: 0.5204\n",
      "Epoch 2/100\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.6898 - accuracy: 0.5179 - val_loss: 0.6868 - val_accuracy: 0.5306\n",
      "Epoch 3/100\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.6861 - accuracy: 0.5308 - val_loss: 0.6854 - val_accuracy: 0.5408\n",
      "Epoch 4/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.6824 - accuracy: 0.5610 - val_loss: 0.6849 - val_accuracy: 0.5408\n",
      "Epoch 5/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.6785 - accuracy: 0.5739 - val_loss: 0.6869 - val_accuracy: 0.5357\n",
      "Epoch 6/100\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.6732 - accuracy: 0.5854 - val_loss: 0.6871 - val_accuracy: 0.5459\n",
      "Epoch 7/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.6679 - accuracy: 0.5925 - val_loss: 0.6875 - val_accuracy: 0.5357\n",
      "Epoch 8/100\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.6624 - accuracy: 0.6011 - val_loss: 0.6925 - val_accuracy: 0.5204\n",
      "Epoch 9/100\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.6566 - accuracy: 0.6055 - val_loss: 0.6957 - val_accuracy: 0.5153\n",
      "Epoch 10/100\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.6523 - accuracy: 0.6112 - val_loss: 0.7001 - val_accuracy: 0.5153\n",
      "Epoch 11/100\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.6483 - accuracy: 0.6040 - val_loss: 0.6954 - val_accuracy: 0.5306\n",
      "Epoch 12/100\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.6432 - accuracy: 0.6298 - val_loss: 0.7018 - val_accuracy: 0.5153\n",
      "Epoch 13/100\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.6346 - accuracy: 0.6298 - val_loss: 0.7060 - val_accuracy: 0.5204\n",
      "Epoch 14/100\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.6276 - accuracy: 0.6370 - val_loss: 0.7045 - val_accuracy: 0.5255\n",
      "Epoch 15/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.6177 - accuracy: 0.6471 - val_loss: 0.7103 - val_accuracy: 0.5204\n",
      "Epoch 16/100\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.6110 - accuracy: 0.6628 - val_loss: 0.7162 - val_accuracy: 0.5459\n",
      "Epoch 1/100\n",
      "22/22 [==============================] - 4s 43ms/step - loss: 0.7061 - accuracy: 0.4821 - val_loss: 0.6963 - val_accuracy: 0.5000\n",
      "Epoch 2/100\n",
      "22/22 [==============================] - 0s 14ms/step - loss: 0.6910 - accuracy: 0.5409 - val_loss: 0.6943 - val_accuracy: 0.5255\n",
      "Epoch 3/100\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 0.6877 - accuracy: 0.5466 - val_loss: 0.6924 - val_accuracy: 0.5459\n",
      "Epoch 4/100\n",
      "22/22 [==============================] - 0s 13ms/step - loss: 0.6802 - accuracy: 0.5868 - val_loss: 0.6971 - val_accuracy: 0.5204\n",
      "Epoch 5/100\n",
      "22/22 [==============================] - 0s 17ms/step - loss: 0.6827 - accuracy: 0.5581 - val_loss: 0.6971 - val_accuracy: 0.5255\n",
      "Epoch 6/100\n",
      "22/22 [==============================] - 0s 14ms/step - loss: 0.6754 - accuracy: 0.5624 - val_loss: 0.6930 - val_accuracy: 0.5102\n",
      "Epoch 7/100\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 0.6728 - accuracy: 0.5825 - val_loss: 0.6843 - val_accuracy: 0.5459\n",
      "Epoch 8/100\n",
      "22/22 [==============================] - 0s 16ms/step - loss: 0.6618 - accuracy: 0.5925 - val_loss: 0.6957 - val_accuracy: 0.5561\n",
      "Epoch 9/100\n",
      "22/22 [==============================] - 0s 15ms/step - loss: 0.6445 - accuracy: 0.6098 - val_loss: 0.7367 - val_accuracy: 0.5357\n",
      "Epoch 10/100\n",
      "22/22 [==============================] - 0s 16ms/step - loss: 0.6471 - accuracy: 0.5868 - val_loss: 0.7205 - val_accuracy: 0.5051\n",
      "Epoch 11/100\n",
      "22/22 [==============================] - 0s 15ms/step - loss: 0.6396 - accuracy: 0.6198 - val_loss: 0.7098 - val_accuracy: 0.5765\n",
      "Epoch 12/100\n",
      "22/22 [==============================] - 0s 17ms/step - loss: 0.6120 - accuracy: 0.6743 - val_loss: 0.7577 - val_accuracy: 0.5561\n",
      "Epoch 13/100\n",
      "22/22 [==============================] - 0s 17ms/step - loss: 0.6066 - accuracy: 0.6528 - val_loss: 0.7275 - val_accuracy: 0.5459\n",
      "Epoch 14/100\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 0.5785 - accuracy: 0.6915 - val_loss: 0.7444 - val_accuracy: 0.5867\n",
      "Epoch 15/100\n",
      "22/22 [==============================] - 0s 13ms/step - loss: 0.5784 - accuracy: 0.6815 - val_loss: 0.8124 - val_accuracy: 0.5612\n",
      "Epoch 16/100\n",
      "22/22 [==============================] - 0s 16ms/step - loss: 0.5421 - accuracy: 0.7116 - val_loss: 0.7973 - val_accuracy: 0.5561\n",
      "Epoch 17/100\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 0.4761 - accuracy: 0.7647 - val_loss: 0.8514 - val_accuracy: 0.5918\n",
      "Epoch 18/100\n",
      "22/22 [==============================] - 0s 14ms/step - loss: 0.4725 - accuracy: 0.7747 - val_loss: 0.9557 - val_accuracy: 0.5561\n",
      "Epoch 19/100\n",
      "22/22 [==============================] - 0s 17ms/step - loss: 0.4469 - accuracy: 0.7877 - val_loss: 0.9785 - val_accuracy: 0.5357\n",
      "Epoch 20/100\n",
      "22/22 [==============================] - 0s 15ms/step - loss: 0.3977 - accuracy: 0.8063 - val_loss: 1.0283 - val_accuracy: 0.5204\n",
      "Epoch 21/100\n",
      "22/22 [==============================] - 0s 14ms/step - loss: 0.3845 - accuracy: 0.8207 - val_loss: 1.0194 - val_accuracy: 0.5204\n",
      "Epoch 22/100\n",
      "22/22 [==============================] - 0s 13ms/step - loss: 0.3159 - accuracy: 0.8623 - val_loss: 1.1528 - val_accuracy: 0.5102\n",
      "Epoch 23/100\n",
      "22/22 [==============================] - 0s 16ms/step - loss: 0.2698 - accuracy: 0.8824 - val_loss: 1.3213 - val_accuracy: 0.4949\n",
      "Epoch 24/100\n",
      "22/22 [==============================] - 0s 13ms/step - loss: 0.2431 - accuracy: 0.8967 - val_loss: 1.3178 - val_accuracy: 0.5357\n",
      "Epoch 25/100\n",
      "22/22 [==============================] - 0s 15ms/step - loss: 0.2490 - accuracy: 0.9039 - val_loss: 1.3647 - val_accuracy: 0.4949\n",
      "Epoch 26/100\n",
      "22/22 [==============================] - 0s 17ms/step - loss: 0.1988 - accuracy: 0.9211 - val_loss: 1.5488 - val_accuracy: 0.4847\n",
      "Epoch 27/100\n",
      "22/22 [==============================] - 0s 15ms/step - loss: 0.1797 - accuracy: 0.9283 - val_loss: 1.6264 - val_accuracy: 0.5153\n",
      "Epoch 1/100\n",
      "22/22 [==============================] - 4s 50ms/step - loss: 0.6968 - accuracy: 0.4921 - val_loss: 0.7004 - val_accuracy: 0.4337\n",
      "Epoch 2/100\n",
      "22/22 [==============================] - 0s 19ms/step - loss: 0.6961 - accuracy: 0.5151 - val_loss: 0.6982 - val_accuracy: 0.4694\n",
      "Epoch 3/100\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 0.6926 - accuracy: 0.5323 - val_loss: 0.6970 - val_accuracy: 0.4592\n",
      "Epoch 4/100\n",
      "22/22 [==============================] - 0s 20ms/step - loss: 0.6905 - accuracy: 0.5294 - val_loss: 0.6963 - val_accuracy: 0.4745\n",
      "Epoch 5/100\n",
      "22/22 [==============================] - 0s 14ms/step - loss: 0.6906 - accuracy: 0.5352 - val_loss: 0.6961 - val_accuracy: 0.4643\n",
      "Epoch 6/100\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 0.6893 - accuracy: 0.5337 - val_loss: 0.6956 - val_accuracy: 0.4490\n",
      "Epoch 7/100\n",
      "22/22 [==============================] - 0s 19ms/step - loss: 0.6871 - accuracy: 0.5308 - val_loss: 0.6956 - val_accuracy: 0.4439\n",
      "Epoch 8/100\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 0.6908 - accuracy: 0.5352 - val_loss: 0.6954 - val_accuracy: 0.4745\n",
      "Epoch 9/100\n",
      "22/22 [==============================] - 0s 20ms/step - loss: 0.6889 - accuracy: 0.5366 - val_loss: 0.6954 - val_accuracy: 0.4796\n",
      "Epoch 10/100\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 0.6891 - accuracy: 0.5581 - val_loss: 0.6952 - val_accuracy: 0.4949\n",
      "Epoch 11/100\n",
      "22/22 [==============================] - 1s 23ms/step - loss: 0.6896 - accuracy: 0.5395 - val_loss: 0.6953 - val_accuracy: 0.4949\n",
      "Epoch 12/100\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 0.6880 - accuracy: 0.5481 - val_loss: 0.6954 - val_accuracy: 0.5000\n",
      "Epoch 13/100\n",
      "22/22 [==============================] - 0s 20ms/step - loss: 0.6859 - accuracy: 0.5581 - val_loss: 0.6954 - val_accuracy: 0.4949\n",
      "Epoch 14/100\n",
      "22/22 [==============================] - 0s 22ms/step - loss: 0.6878 - accuracy: 0.5509 - val_loss: 0.6954 - val_accuracy: 0.4898\n",
      "Epoch 15/100\n",
      "22/22 [==============================] - 0s 20ms/step - loss: 0.6893 - accuracy: 0.5438 - val_loss: 0.6956 - val_accuracy: 0.4847\n",
      "Epoch 16/100\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 0.6838 - accuracy: 0.5595 - val_loss: 0.6957 - val_accuracy: 0.5000\n",
      "Epoch 17/100\n",
      "22/22 [==============================] - 0s 19ms/step - loss: 0.6854 - accuracy: 0.5495 - val_loss: 0.6956 - val_accuracy: 0.5000\n",
      "Epoch 18/100\n",
      "22/22 [==============================] - 0s 22ms/step - loss: 0.6890 - accuracy: 0.5380 - val_loss: 0.6956 - val_accuracy: 0.5051\n",
      "Epoch 19/100\n",
      "22/22 [==============================] - 0s 19ms/step - loss: 0.6881 - accuracy: 0.5395 - val_loss: 0.6958 - val_accuracy: 0.5000\n",
      "Epoch 20/100\n",
      "22/22 [==============================] - 0s 22ms/step - loss: 0.6861 - accuracy: 0.5581 - val_loss: 0.6956 - val_accuracy: 0.5000\n",
      "Epoch 21/100\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 0.6862 - accuracy: 0.5653 - val_loss: 0.6958 - val_accuracy: 0.4949\n",
      "Epoch 22/100\n",
      "22/22 [==============================] - 0s 16ms/step - loss: 0.6845 - accuracy: 0.5624 - val_loss: 0.6958 - val_accuracy: 0.5051\n",
      "Epoch 23/100\n",
      "22/22 [==============================] - 0s 19ms/step - loss: 0.6847 - accuracy: 0.5681 - val_loss: 0.6958 - val_accuracy: 0.4949\n",
      "Epoch 24/100\n",
      "22/22 [==============================] - 0s 22ms/step - loss: 0.6856 - accuracy: 0.5438 - val_loss: 0.6960 - val_accuracy: 0.5000\n",
      "Epoch 25/100\n",
      "22/22 [==============================] - 0s 17ms/step - loss: 0.6845 - accuracy: 0.5681 - val_loss: 0.6959 - val_accuracy: 0.5051\n",
      "Epoch 26/100\n",
      "22/22 [==============================] - 0s 15ms/step - loss: 0.6864 - accuracy: 0.5696 - val_loss: 0.6958 - val_accuracy: 0.5051\n",
      "Epoch 27/100\n",
      "22/22 [==============================] - 0s 20ms/step - loss: 0.6843 - accuracy: 0.5524 - val_loss: 0.6959 - val_accuracy: 0.5051\n",
      "Epoch 28/100\n",
      "22/22 [==============================] - 0s 22ms/step - loss: 0.6825 - accuracy: 0.5739 - val_loss: 0.6958 - val_accuracy: 0.5000\n",
      "Epoch 1/100\n",
      "22/22 [==============================] - 3s 39ms/step - loss: 0.7030 - accuracy: 0.4935 - val_loss: 0.6999 - val_accuracy: 0.4439\n",
      "Epoch 2/100\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6994 - accuracy: 0.4849 - val_loss: 0.6984 - val_accuracy: 0.4388\n",
      "Epoch 3/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.6951 - accuracy: 0.5022 - val_loss: 0.6973 - val_accuracy: 0.4847\n",
      "Epoch 4/100\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.6945 - accuracy: 0.5237 - val_loss: 0.6958 - val_accuracy: 0.5000\n",
      "Epoch 5/100\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.6961 - accuracy: 0.4993 - val_loss: 0.6955 - val_accuracy: 0.5204\n",
      "Epoch 6/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.6848 - accuracy: 0.5423 - val_loss: 0.6949 - val_accuracy: 0.5153\n",
      "Epoch 7/100\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.6905 - accuracy: 0.5323 - val_loss: 0.6952 - val_accuracy: 0.5102\n",
      "Epoch 8/100\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.6868 - accuracy: 0.5409 - val_loss: 0.6944 - val_accuracy: 0.5153\n",
      "Epoch 9/100\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.6852 - accuracy: 0.5265 - val_loss: 0.6946 - val_accuracy: 0.4949\n",
      "Epoch 10/100\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.6870 - accuracy: 0.5452 - val_loss: 0.6949 - val_accuracy: 0.4949\n",
      "Epoch 11/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.6879 - accuracy: 0.5438 - val_loss: 0.6957 - val_accuracy: 0.4949\n",
      "Epoch 12/100\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.6811 - accuracy: 0.5423 - val_loss: 0.6955 - val_accuracy: 0.4796\n",
      "Epoch 13/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 8ms/step - loss: 0.6838 - accuracy: 0.5897 - val_loss: 0.6969 - val_accuracy: 0.4847\n",
      "Epoch 14/100\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.6759 - accuracy: 0.5796 - val_loss: 0.6977 - val_accuracy: 0.4796\n",
      "Epoch 15/100\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.6809 - accuracy: 0.5667 - val_loss: 0.6992 - val_accuracy: 0.4796\n",
      "Epoch 1/100\n",
      "22/22 [==============================] - 4s 54ms/step - loss: 0.7104 - accuracy: 0.5036 - val_loss: 0.7041 - val_accuracy: 0.5051\n",
      "Epoch 2/100\n",
      "22/22 [==============================] - 1s 27ms/step - loss: 0.6954 - accuracy: 0.5395 - val_loss: 0.6978 - val_accuracy: 0.5000\n",
      "Epoch 3/100\n",
      "22/22 [==============================] - 1s 27ms/step - loss: 0.6935 - accuracy: 0.5337 - val_loss: 0.6944 - val_accuracy: 0.5102\n",
      "Epoch 4/100\n",
      "22/22 [==============================] - 0s 22ms/step - loss: 0.6811 - accuracy: 0.5509 - val_loss: 0.6953 - val_accuracy: 0.5051\n",
      "Epoch 5/100\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 0.6803 - accuracy: 0.5538 - val_loss: 0.6894 - val_accuracy: 0.5102\n",
      "Epoch 6/100\n",
      "22/22 [==============================] - 1s 26ms/step - loss: 0.6739 - accuracy: 0.5768 - val_loss: 0.7033 - val_accuracy: 0.5153\n",
      "Epoch 7/100\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 0.6714 - accuracy: 0.5552 - val_loss: 0.7046 - val_accuracy: 0.5204\n",
      "Epoch 8/100\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 0.6652 - accuracy: 0.5868 - val_loss: 0.7165 - val_accuracy: 0.5051\n",
      "Epoch 9/100\n",
      "22/22 [==============================] - 1s 23ms/step - loss: 0.6663 - accuracy: 0.5811 - val_loss: 0.6904 - val_accuracy: 0.5153\n",
      "Epoch 10/100\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 0.6392 - accuracy: 0.6098 - val_loss: 0.7650 - val_accuracy: 0.5051\n",
      "Epoch 11/100\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 0.6340 - accuracy: 0.6212 - val_loss: 0.7306 - val_accuracy: 0.5255\n",
      "Epoch 12/100\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 0.6210 - accuracy: 0.6313 - val_loss: 0.7818 - val_accuracy: 0.4592\n",
      "Epoch 13/100\n",
      "22/22 [==============================] - 1s 26ms/step - loss: 0.5841 - accuracy: 0.6643 - val_loss: 0.8115 - val_accuracy: 0.5000\n",
      "Epoch 14/100\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 0.5634 - accuracy: 0.6958 - val_loss: 0.7872 - val_accuracy: 0.5306\n",
      "Epoch 15/100\n",
      "22/22 [==============================] - 1s 29ms/step - loss: 0.5359 - accuracy: 0.7303 - val_loss: 0.7666 - val_accuracy: 0.5357\n",
      "Epoch 16/100\n",
      "22/22 [==============================] - 1s 26ms/step - loss: 0.5001 - accuracy: 0.7331 - val_loss: 0.9947 - val_accuracy: 0.5255\n",
      "Epoch 17/100\n",
      "22/22 [==============================] - 1s 27ms/step - loss: 0.4646 - accuracy: 0.7719 - val_loss: 0.8899 - val_accuracy: 0.4847\n",
      "Epoch 18/100\n",
      "22/22 [==============================] - 1s 27ms/step - loss: 0.4221 - accuracy: 0.7877 - val_loss: 0.9242 - val_accuracy: 0.5153\n",
      "Epoch 19/100\n",
      "22/22 [==============================] - 1s 26ms/step - loss: 0.3813 - accuracy: 0.7963 - val_loss: 1.1313 - val_accuracy: 0.5408\n",
      "Epoch 20/100\n",
      "22/22 [==============================] - 1s 27ms/step - loss: 0.3069 - accuracy: 0.8594 - val_loss: 1.1591 - val_accuracy: 0.5000\n",
      "Epoch 21/100\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 0.2853 - accuracy: 0.8824 - val_loss: 1.3966 - val_accuracy: 0.5153\n",
      "Epoch 22/100\n",
      "22/22 [==============================] - 1s 26ms/step - loss: 0.2458 - accuracy: 0.9053 - val_loss: 1.4320 - val_accuracy: 0.5000\n",
      "Epoch 23/100\n",
      "22/22 [==============================] - 0s 20ms/step - loss: 0.1951 - accuracy: 0.9283 - val_loss: 1.3652 - val_accuracy: 0.5306\n",
      "Epoch 24/100\n",
      "22/22 [==============================] - 1s 23ms/step - loss: 0.1646 - accuracy: 0.9455 - val_loss: 1.5857 - val_accuracy: 0.5255\n",
      "Epoch 25/100\n",
      "22/22 [==============================] - 1s 28ms/step - loss: 0.1349 - accuracy: 0.9412 - val_loss: 1.7254 - val_accuracy: 0.4949\n",
      "Epoch 26/100\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 0.1589 - accuracy: 0.9383 - val_loss: 1.5540 - val_accuracy: 0.5612\n",
      "Epoch 27/100\n",
      "22/22 [==============================] - 1s 28ms/step - loss: 0.1212 - accuracy: 0.9555 - val_loss: 1.7098 - val_accuracy: 0.5102\n",
      "Epoch 28/100\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 0.1333 - accuracy: 0.9512 - val_loss: 1.6739 - val_accuracy: 0.5255\n",
      "Epoch 29/100\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 0.0893 - accuracy: 0.9684 - val_loss: 1.6356 - val_accuracy: 0.5357\n",
      "Epoch 30/100\n",
      "22/22 [==============================] - 1s 28ms/step - loss: 0.0528 - accuracy: 0.9857 - val_loss: 1.8931 - val_accuracy: 0.4592\n",
      "Epoch 31/100\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 0.0542 - accuracy: 0.9871 - val_loss: 1.8689 - val_accuracy: 0.5153\n",
      "Epoch 32/100\n",
      "22/22 [==============================] - 0s 22ms/step - loss: 0.0289 - accuracy: 0.9928 - val_loss: 1.9381 - val_accuracy: 0.5102\n",
      "Epoch 33/100\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 0.0542 - accuracy: 0.9857 - val_loss: 2.1386 - val_accuracy: 0.4949\n",
      "Epoch 34/100\n",
      "22/22 [==============================] - 1s 27ms/step - loss: 0.0654 - accuracy: 0.9813 - val_loss: 1.9883 - val_accuracy: 0.5000\n",
      "Epoch 35/100\n",
      "22/22 [==============================] - 1s 26ms/step - loss: 0.0705 - accuracy: 0.9742 - val_loss: 1.8891 - val_accuracy: 0.5102\n",
      "Epoch 36/100\n",
      "22/22 [==============================] - 1s 26ms/step - loss: 0.0240 - accuracy: 0.9957 - val_loss: 2.0438 - val_accuracy: 0.5306\n",
      "Epoch 1/100\n",
      "22/22 [==============================] - 3s 44ms/step - loss: 0.6987 - accuracy: 0.5065 - val_loss: 0.6870 - val_accuracy: 0.5204\n",
      "Epoch 2/100\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 0.6866 - accuracy: 0.5610 - val_loss: 0.6950 - val_accuracy: 0.5255\n",
      "Epoch 3/100\n",
      "22/22 [==============================] - 0s 19ms/step - loss: 0.6845 - accuracy: 0.5567 - val_loss: 0.6941 - val_accuracy: 0.5051\n",
      "Epoch 4/100\n",
      "22/22 [==============================] - 0s 17ms/step - loss: 0.6771 - accuracy: 0.5753 - val_loss: 0.6865 - val_accuracy: 0.5459\n",
      "Epoch 5/100\n",
      "22/22 [==============================] - 0s 15ms/step - loss: 0.6764 - accuracy: 0.5638 - val_loss: 0.6906 - val_accuracy: 0.5306\n",
      "Epoch 6/100\n",
      "22/22 [==============================] - 0s 17ms/step - loss: 0.6716 - accuracy: 0.5753 - val_loss: 0.6956 - val_accuracy: 0.5459\n",
      "Epoch 7/100\n",
      "22/22 [==============================] - 0s 19ms/step - loss: 0.6606 - accuracy: 0.6026 - val_loss: 0.6896 - val_accuracy: 0.5459\n",
      "Epoch 8/100\n",
      "22/22 [==============================] - 0s 16ms/step - loss: 0.6577 - accuracy: 0.5925 - val_loss: 0.6866 - val_accuracy: 0.5714\n",
      "Epoch 9/100\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 0.6552 - accuracy: 0.6026 - val_loss: 0.6938 - val_accuracy: 0.5816\n",
      "Epoch 10/100\n",
      "22/22 [==============================] - 0s 17ms/step - loss: 0.6427 - accuracy: 0.5954 - val_loss: 0.7003 - val_accuracy: 0.5510\n",
      "Epoch 11/100\n",
      "22/22 [==============================] - 0s 19ms/step - loss: 0.6329 - accuracy: 0.6169 - val_loss: 0.7303 - val_accuracy: 0.5357\n",
      "Epoch 12/100\n",
      "22/22 [==============================] - 0s 19ms/step - loss: 0.6177 - accuracy: 0.6471 - val_loss: 0.7221 - val_accuracy: 0.5510\n",
      "Epoch 13/100\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 0.6068 - accuracy: 0.6585 - val_loss: 0.7377 - val_accuracy: 0.5561\n",
      "Epoch 14/100\n",
      "22/22 [==============================] - 0s 20ms/step - loss: 0.5822 - accuracy: 0.6714 - val_loss: 0.7670 - val_accuracy: 0.5612\n",
      "Epoch 15/100\n",
      "22/22 [==============================] - 0s 19ms/step - loss: 0.5664 - accuracy: 0.6930 - val_loss: 0.8177 - val_accuracy: 0.5357\n",
      "Epoch 16/100\n",
      "22/22 [==============================] - 0s 13ms/step - loss: 0.5403 - accuracy: 0.7202 - val_loss: 0.7993 - val_accuracy: 0.5357\n",
      "Epoch 17/100\n",
      "22/22 [==============================] - 0s 17ms/step - loss: 0.5066 - accuracy: 0.7274 - val_loss: 0.8872 - val_accuracy: 0.5051\n",
      "Epoch 18/100\n",
      "22/22 [==============================] - 0s 22ms/step - loss: 0.5111 - accuracy: 0.7360 - val_loss: 0.8641 - val_accuracy: 0.5102\n",
      "Epoch 19/100\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 0.4806 - accuracy: 0.7647 - val_loss: 0.8819 - val_accuracy: 0.5561\n",
      "Epoch 1/100\n",
      "22/22 [==============================] - 4s 37ms/step - loss: 0.7066 - accuracy: 0.5323 - val_loss: 0.7009 - val_accuracy: 0.5051\n",
      "Epoch 2/100\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.7239 - accuracy: 0.4849 - val_loss: 0.7008 - val_accuracy: 0.5051\n",
      "Epoch 3/100\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.7112 - accuracy: 0.5165 - val_loss: 0.7007 - val_accuracy: 0.5102\n",
      "Epoch 4/100\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.7176 - accuracy: 0.5065 - val_loss: 0.7005 - val_accuracy: 0.5102\n",
      "Epoch 5/100\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.7138 - accuracy: 0.4964 - val_loss: 0.7004 - val_accuracy: 0.5153\n",
      "Epoch 6/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.7206 - accuracy: 0.4978 - val_loss: 0.7003 - val_accuracy: 0.5204\n",
      "Epoch 7/100\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.7207 - accuracy: 0.5237 - val_loss: 0.7002 - val_accuracy: 0.5204\n",
      "Epoch 8/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.7123 - accuracy: 0.4978 - val_loss: 0.7000 - val_accuracy: 0.5204\n",
      "Epoch 9/100\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.7051 - accuracy: 0.5251 - val_loss: 0.6999 - val_accuracy: 0.5204\n",
      "Epoch 10/100\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.7195 - accuracy: 0.4935 - val_loss: 0.6998 - val_accuracy: 0.5204\n",
      "Epoch 11/100\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.7144 - accuracy: 0.4892 - val_loss: 0.6998 - val_accuracy: 0.5153\n",
      "Epoch 12/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.7203 - accuracy: 0.5022 - val_loss: 0.6996 - val_accuracy: 0.5153\n",
      "Epoch 13/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.7096 - accuracy: 0.4935 - val_loss: 0.6994 - val_accuracy: 0.5153\n",
      "Epoch 14/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.7069 - accuracy: 0.5165 - val_loss: 0.6993 - val_accuracy: 0.5153\n",
      "Epoch 15/100\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.7088 - accuracy: 0.5108 - val_loss: 0.6992 - val_accuracy: 0.5153\n",
      "Epoch 16/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.7132 - accuracy: 0.5165 - val_loss: 0.6991 - val_accuracy: 0.5153\n",
      "Epoch 1/100\n",
      "22/22 [==============================] - 3s 35ms/step - loss: 0.6986 - accuracy: 0.4993 - val_loss: 0.6969 - val_accuracy: 0.4898\n",
      "Epoch 2/100\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.6867 - accuracy: 0.5395 - val_loss: 0.6974 - val_accuracy: 0.4898\n",
      "Epoch 3/100\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.6811 - accuracy: 0.5667 - val_loss: 0.6974 - val_accuracy: 0.5051\n",
      "Epoch 4/100\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.6755 - accuracy: 0.5811 - val_loss: 0.6961 - val_accuracy: 0.5255\n",
      "Epoch 5/100\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.6668 - accuracy: 0.5925 - val_loss: 0.6995 - val_accuracy: 0.5306\n",
      "Epoch 6/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.6616 - accuracy: 0.5954 - val_loss: 0.7095 - val_accuracy: 0.5102\n",
      "Epoch 7/100\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.6522 - accuracy: 0.6141 - val_loss: 0.7009 - val_accuracy: 0.5102\n",
      "Epoch 8/100\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.6436 - accuracy: 0.6284 - val_loss: 0.7112 - val_accuracy: 0.5459\n",
      "Epoch 9/100\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.6343 - accuracy: 0.6356 - val_loss: 0.7170 - val_accuracy: 0.5408\n",
      "Epoch 10/100\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.6225 - accuracy: 0.6428 - val_loss: 0.7168 - val_accuracy: 0.5408\n",
      "Epoch 11/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.6151 - accuracy: 0.6499 - val_loss: 0.7295 - val_accuracy: 0.5306\n",
      "Epoch 12/100\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.6008 - accuracy: 0.6743 - val_loss: 0.7355 - val_accuracy: 0.5255\n",
      "Epoch 13/100\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.5932 - accuracy: 0.6815 - val_loss: 0.7363 - val_accuracy: 0.5408\n",
      "Epoch 14/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.5760 - accuracy: 0.6958 - val_loss: 0.7486 - val_accuracy: 0.5306\n",
      "Epoch 15/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.5684 - accuracy: 0.7001 - val_loss: 0.7595 - val_accuracy: 0.5510\n",
      "Epoch 16/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.5592 - accuracy: 0.7102 - val_loss: 0.7661 - val_accuracy: 0.5153\n",
      "Epoch 17/100\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.5401 - accuracy: 0.7360 - val_loss: 0.7895 - val_accuracy: 0.5306\n",
      "Epoch 18/100\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.5391 - accuracy: 0.7088 - val_loss: 0.7926 - val_accuracy: 0.5102\n",
      "Epoch 19/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.5252 - accuracy: 0.7346 - val_loss: 0.7801 - val_accuracy: 0.5102\n",
      "Epoch 20/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.5128 - accuracy: 0.7317 - val_loss: 0.8054 - val_accuracy: 0.4949\n",
      "Epoch 21/100\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.5072 - accuracy: 0.7346 - val_loss: 0.7904 - val_accuracy: 0.5306\n",
      "Epoch 22/100\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.4863 - accuracy: 0.7647 - val_loss: 0.8261 - val_accuracy: 0.5051\n",
      "Epoch 23/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.4712 - accuracy: 0.7690 - val_loss: 0.8237 - val_accuracy: 0.5153\n",
      "Epoch 24/100\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.4654 - accuracy: 0.7762 - val_loss: 0.8471 - val_accuracy: 0.5204\n",
      "Epoch 25/100\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.4580 - accuracy: 0.7733 - val_loss: 0.8529 - val_accuracy: 0.5357\n",
      "Epoch 1/100\n",
      "22/22 [==============================] - 4s 46ms/step - loss: 0.7067 - accuracy: 0.5265 - val_loss: 0.7004 - val_accuracy: 0.5408\n",
      "Epoch 2/100\n",
      "22/22 [==============================] - 0s 19ms/step - loss: 0.6958 - accuracy: 0.5438 - val_loss: 0.6956 - val_accuracy: 0.4745\n",
      "Epoch 3/100\n",
      "22/22 [==============================] - 0s 16ms/step - loss: 0.6866 - accuracy: 0.5509 - val_loss: 0.6964 - val_accuracy: 0.5153\n",
      "Epoch 4/100\n",
      "22/22 [==============================] - 0s 17ms/step - loss: 0.6931 - accuracy: 0.5509 - val_loss: 0.6907 - val_accuracy: 0.5051\n",
      "Epoch 5/100\n",
      "22/22 [==============================] - 0s 20ms/step - loss: 0.6870 - accuracy: 0.5581 - val_loss: 0.7026 - val_accuracy: 0.5459\n",
      "Epoch 6/100\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 0.6804 - accuracy: 0.5653 - val_loss: 0.6886 - val_accuracy: 0.5357\n",
      "Epoch 7/100\n",
      "22/22 [==============================] - 0s 22ms/step - loss: 0.6875 - accuracy: 0.5552 - val_loss: 0.6899 - val_accuracy: 0.5357\n",
      "Epoch 8/100\n",
      "22/22 [==============================] - 0s 17ms/step - loss: 0.6596 - accuracy: 0.6083 - val_loss: 0.7366 - val_accuracy: 0.5408\n",
      "Epoch 9/100\n",
      "22/22 [==============================] - 0s 17ms/step - loss: 0.6678 - accuracy: 0.5897 - val_loss: 0.6857 - val_accuracy: 0.5612\n",
      "Epoch 10/100\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 0.6492 - accuracy: 0.6112 - val_loss: 0.7636 - val_accuracy: 0.5663\n",
      "Epoch 11/100\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 0.6350 - accuracy: 0.6385 - val_loss: 0.7038 - val_accuracy: 0.5561\n",
      "Epoch 12/100\n",
      "22/22 [==============================] - 0s 17ms/step - loss: 0.6110 - accuracy: 0.6542 - val_loss: 0.7550 - val_accuracy: 0.5459\n",
      "Epoch 13/100\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.5865 - accuracy: 0.6887 - val_loss: 0.7662 - val_accuracy: 0.5408\n",
      "Epoch 14/100\n",
      "22/22 [==============================] - 0s 19ms/step - loss: 0.5564 - accuracy: 0.6944 - val_loss: 0.7993 - val_accuracy: 0.5663\n",
      "Epoch 15/100\n",
      "22/22 [==============================] - 0s 20ms/step - loss: 0.5158 - accuracy: 0.7202 - val_loss: 0.7935 - val_accuracy: 0.5510\n",
      "Epoch 16/100\n",
      "22/22 [==============================] - 0s 19ms/step - loss: 0.4706 - accuracy: 0.7676 - val_loss: 0.8811 - val_accuracy: 0.5765\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/100\n",
      "22/22 [==============================] - 0s 16ms/step - loss: 0.4428 - accuracy: 0.7862 - val_loss: 0.8660 - val_accuracy: 0.5714\n",
      "Epoch 18/100\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 0.4212 - accuracy: 0.8106 - val_loss: 0.9437 - val_accuracy: 0.5714\n",
      "Epoch 19/100\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 0.3801 - accuracy: 0.8321 - val_loss: 0.9872 - val_accuracy: 0.5408\n",
      "Epoch 20/100\n",
      "22/22 [==============================] - 0s 17ms/step - loss: 0.3379 - accuracy: 0.8565 - val_loss: 1.1299 - val_accuracy: 0.5510\n",
      "Epoch 21/100\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 0.2869 - accuracy: 0.8795 - val_loss: 1.1312 - val_accuracy: 0.5459\n",
      "Epoch 22/100\n",
      "22/22 [==============================] - 0s 19ms/step - loss: 0.2316 - accuracy: 0.9096 - val_loss: 1.2200 - val_accuracy: 0.5867\n",
      "Epoch 23/100\n",
      "22/22 [==============================] - 0s 20ms/step - loss: 0.1809 - accuracy: 0.9283 - val_loss: 1.4574 - val_accuracy: 0.5357\n",
      "Epoch 24/100\n",
      "22/22 [==============================] - 0s 17ms/step - loss: 0.1220 - accuracy: 0.9684 - val_loss: 1.5356 - val_accuracy: 0.5510\n",
      "Epoch 25/100\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 0.1109 - accuracy: 0.9670 - val_loss: 1.6941 - val_accuracy: 0.5459\n",
      "Epoch 26/100\n",
      "22/22 [==============================] - 0s 17ms/step - loss: 0.0850 - accuracy: 0.9727 - val_loss: 1.8204 - val_accuracy: 0.5714\n",
      "Epoch 27/100\n",
      "22/22 [==============================] - 0s 19ms/step - loss: 0.1218 - accuracy: 0.9555 - val_loss: 1.8156 - val_accuracy: 0.5867\n",
      "Epoch 28/100\n",
      "22/22 [==============================] - 0s 19ms/step - loss: 0.1315 - accuracy: 0.9527 - val_loss: 1.7460 - val_accuracy: 0.5816\n",
      "Epoch 29/100\n",
      "22/22 [==============================] - 0s 15ms/step - loss: 0.1387 - accuracy: 0.9570 - val_loss: 1.6642 - val_accuracy: 0.5765\n",
      "Epoch 30/100\n",
      "22/22 [==============================] - 0s 17ms/step - loss: 0.1161 - accuracy: 0.9684 - val_loss: 1.5998 - val_accuracy: 0.5765\n",
      "Epoch 31/100\n",
      "22/22 [==============================] - 0s 17ms/step - loss: 0.0756 - accuracy: 0.9842 - val_loss: 1.7614 - val_accuracy: 0.5612\n",
      "Epoch 32/100\n",
      "22/22 [==============================] - 0s 20ms/step - loss: 0.0476 - accuracy: 0.9842 - val_loss: 1.8766 - val_accuracy: 0.5459\n",
      "Epoch 1/100\n",
      "22/22 [==============================] - 3s 35ms/step - loss: 0.6975 - accuracy: 0.4978 - val_loss: 0.6965 - val_accuracy: 0.5102\n",
      "Epoch 2/100\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.6870 - accuracy: 0.5481 - val_loss: 0.6965 - val_accuracy: 0.5408\n",
      "Epoch 3/100\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.6804 - accuracy: 0.5739 - val_loss: 0.6959 - val_accuracy: 0.5357\n",
      "Epoch 4/100\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.6766 - accuracy: 0.5753 - val_loss: 0.6980 - val_accuracy: 0.5408\n",
      "Epoch 5/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.6683 - accuracy: 0.5811 - val_loss: 0.6990 - val_accuracy: 0.5357\n",
      "Epoch 6/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.6614 - accuracy: 0.5968 - val_loss: 0.6981 - val_accuracy: 0.5612\n",
      "Epoch 7/100\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.6552 - accuracy: 0.6155 - val_loss: 0.7018 - val_accuracy: 0.5612\n",
      "Epoch 8/100\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.6476 - accuracy: 0.6212 - val_loss: 0.7059 - val_accuracy: 0.5663\n",
      "Epoch 9/100\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.6393 - accuracy: 0.6198 - val_loss: 0.7079 - val_accuracy: 0.5612\n",
      "Epoch 10/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.6370 - accuracy: 0.6270 - val_loss: 0.7067 - val_accuracy: 0.5612\n",
      "Epoch 11/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.6231 - accuracy: 0.6485 - val_loss: 0.7065 - val_accuracy: 0.5612\n",
      "Epoch 12/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.6140 - accuracy: 0.6628 - val_loss: 0.7053 - val_accuracy: 0.5714\n",
      "Epoch 13/100\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.6051 - accuracy: 0.6743 - val_loss: 0.7131 - val_accuracy: 0.5663\n",
      "Epoch 14/100\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.5916 - accuracy: 0.6743 - val_loss: 0.7301 - val_accuracy: 0.5816\n",
      "Epoch 15/100\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.5802 - accuracy: 0.6915 - val_loss: 0.7147 - val_accuracy: 0.5867\n",
      "Epoch 16/100\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.5717 - accuracy: 0.7073 - val_loss: 0.7259 - val_accuracy: 0.5714\n",
      "Epoch 17/100\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.5599 - accuracy: 0.6987 - val_loss: 0.7312 - val_accuracy: 0.5918\n",
      "Epoch 18/100\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.5483 - accuracy: 0.7202 - val_loss: 0.7610 - val_accuracy: 0.5765\n",
      "Epoch 19/100\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.5332 - accuracy: 0.7260 - val_loss: 0.7388 - val_accuracy: 0.5918\n",
      "Epoch 20/100\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.5154 - accuracy: 0.7547 - val_loss: 0.7771 - val_accuracy: 0.5969\n",
      "Epoch 21/100\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.5031 - accuracy: 0.7661 - val_loss: 0.7830 - val_accuracy: 0.5969\n",
      "Epoch 22/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.4902 - accuracy: 0.7733 - val_loss: 0.8063 - val_accuracy: 0.5816\n",
      "Epoch 23/100\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.4723 - accuracy: 0.7819 - val_loss: 0.8025 - val_accuracy: 0.5969\n",
      "Epoch 24/100\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.4680 - accuracy: 0.7776 - val_loss: 0.8307 - val_accuracy: 0.5867\n",
      "Epoch 25/100\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.4554 - accuracy: 0.7920 - val_loss: 0.8813 - val_accuracy: 0.5816\n",
      "Epoch 26/100\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.4343 - accuracy: 0.8235 - val_loss: 0.9005 - val_accuracy: 0.5714\n",
      "Epoch 27/100\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.4248 - accuracy: 0.8106 - val_loss: 0.9165 - val_accuracy: 0.5714\n",
      "Epoch 28/100\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.4131 - accuracy: 0.8092 - val_loss: 0.9464 - val_accuracy: 0.5561\n",
      "Epoch 29/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.3981 - accuracy: 0.8250 - val_loss: 0.9822 - val_accuracy: 0.5714\n",
      "Epoch 30/100\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.3894 - accuracy: 0.8264 - val_loss: 0.9695 - val_accuracy: 0.5408\n",
      "iteration 15 – lstm_size:10, dropout:0, learning_rate:0.007525, epochs:20, loss:0.5154, accuracy:0.7547, val_loss:0.7771, val_accuracy:0.5969\n",
      "Epoch 1/100\n",
      "22/22 [==============================] - 4s 44ms/step - loss: 0.6924 - accuracy: 0.5007 - val_loss: 0.6948 - val_accuracy: 0.4745\n",
      "Epoch 2/100\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6922 - accuracy: 0.5222 - val_loss: 0.6945 - val_accuracy: 0.4643\n",
      "Epoch 3/100\n",
      "22/22 [==============================] - 0s 17ms/step - loss: 0.6944 - accuracy: 0.5050 - val_loss: 0.6943 - val_accuracy: 0.4796\n",
      "Epoch 4/100\n",
      "22/22 [==============================] - 0s 14ms/step - loss: 0.6919 - accuracy: 0.5007 - val_loss: 0.6942 - val_accuracy: 0.5000\n",
      "Epoch 5/100\n",
      "22/22 [==============================] - 0s 16ms/step - loss: 0.6934 - accuracy: 0.4993 - val_loss: 0.6940 - val_accuracy: 0.5000\n",
      "Epoch 6/100\n",
      "22/22 [==============================] - 0s 15ms/step - loss: 0.6924 - accuracy: 0.5251 - val_loss: 0.6938 - val_accuracy: 0.4949\n",
      "Epoch 7/100\n",
      "22/22 [==============================] - 0s 16ms/step - loss: 0.6927 - accuracy: 0.4978 - val_loss: 0.6936 - val_accuracy: 0.4949\n",
      "Epoch 8/100\n",
      "22/22 [==============================] - 0s 15ms/step - loss: 0.6898 - accuracy: 0.5179 - val_loss: 0.6936 - val_accuracy: 0.5000\n",
      "Epoch 9/100\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6918 - accuracy: 0.5136 - val_loss: 0.6933 - val_accuracy: 0.5000\n",
      "Epoch 10/100\n",
      "22/22 [==============================] - 0s 16ms/step - loss: 0.6898 - accuracy: 0.5366 - val_loss: 0.6933 - val_accuracy: 0.5000\n",
      "Epoch 11/100\n",
      "22/22 [==============================] - 0s 16ms/step - loss: 0.6906 - accuracy: 0.5251 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 12/100\n",
      "22/22 [==============================] - 0s 15ms/step - loss: 0.6900 - accuracy: 0.5251 - val_loss: 0.6931 - val_accuracy: 0.5051\n",
      "Epoch 13/100\n",
      "22/22 [==============================] - 0s 16ms/step - loss: 0.6874 - accuracy: 0.5552 - val_loss: 0.6931 - val_accuracy: 0.5102\n",
      "Epoch 14/100\n",
      "22/22 [==============================] - 0s 15ms/step - loss: 0.6903 - accuracy: 0.5423 - val_loss: 0.6930 - val_accuracy: 0.5153\n",
      "Epoch 15/100\n",
      "22/22 [==============================] - 0s 14ms/step - loss: 0.6914 - accuracy: 0.5265 - val_loss: 0.6929 - val_accuracy: 0.5204\n",
      "Epoch 16/100\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 0.6886 - accuracy: 0.5438 - val_loss: 0.6929 - val_accuracy: 0.5204\n",
      "Epoch 17/100\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6900 - accuracy: 0.5481 - val_loss: 0.6927 - val_accuracy: 0.5204\n",
      "Epoch 18/100\n",
      "22/22 [==============================] - 0s 14ms/step - loss: 0.6875 - accuracy: 0.5595 - val_loss: 0.6927 - val_accuracy: 0.5255\n",
      "Epoch 19/100\n",
      "22/22 [==============================] - 0s 14ms/step - loss: 0.6878 - accuracy: 0.5409 - val_loss: 0.6927 - val_accuracy: 0.5255\n",
      "Epoch 20/100\n",
      "22/22 [==============================] - 0s 13ms/step - loss: 0.6843 - accuracy: 0.5681 - val_loss: 0.6927 - val_accuracy: 0.5306\n",
      "Epoch 21/100\n",
      "22/22 [==============================] - 0s 15ms/step - loss: 0.6859 - accuracy: 0.5538 - val_loss: 0.6926 - val_accuracy: 0.5255\n",
      "Epoch 22/100\n",
      "22/22 [==============================] - 0s 17ms/step - loss: 0.6862 - accuracy: 0.5495 - val_loss: 0.6926 - val_accuracy: 0.5204\n",
      "Epoch 23/100\n",
      "22/22 [==============================] - 0s 15ms/step - loss: 0.6867 - accuracy: 0.5466 - val_loss: 0.6925 - val_accuracy: 0.5153\n",
      "Epoch 24/100\n",
      "22/22 [==============================] - 0s 15ms/step - loss: 0.6845 - accuracy: 0.5552 - val_loss: 0.6924 - val_accuracy: 0.5204\n",
      "Epoch 25/100\n",
      "22/22 [==============================] - 0s 15ms/step - loss: 0.6879 - accuracy: 0.5567 - val_loss: 0.6924 - val_accuracy: 0.5255\n",
      "Epoch 26/100\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 0.6832 - accuracy: 0.5811 - val_loss: 0.6925 - val_accuracy: 0.5204\n",
      "Epoch 27/100\n",
      "22/22 [==============================] - 0s 14ms/step - loss: 0.6836 - accuracy: 0.5581 - val_loss: 0.6925 - val_accuracy: 0.5255\n",
      "Epoch 28/100\n",
      "22/22 [==============================] - 0s 16ms/step - loss: 0.6858 - accuracy: 0.5466 - val_loss: 0.6925 - val_accuracy: 0.5306\n",
      "Epoch 29/100\n",
      "22/22 [==============================] - 0s 14ms/step - loss: 0.6840 - accuracy: 0.5667 - val_loss: 0.6925 - val_accuracy: 0.5306\n",
      "Epoch 30/100\n",
      "22/22 [==============================] - 0s 20ms/step - loss: 0.6859 - accuracy: 0.5624 - val_loss: 0.6926 - val_accuracy: 0.5306\n",
      "Epoch 1/100\n",
      "22/22 [==============================] - 3s 36ms/step - loss: 0.6973 - accuracy: 0.5079 - val_loss: 0.6864 - val_accuracy: 0.5561\n",
      "Epoch 2/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.6849 - accuracy: 0.5538 - val_loss: 0.6908 - val_accuracy: 0.5357\n",
      "Epoch 3/100\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.6793 - accuracy: 0.5610 - val_loss: 0.6926 - val_accuracy: 0.5153\n",
      "Epoch 4/100\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.6736 - accuracy: 0.5696 - val_loss: 0.6958 - val_accuracy: 0.5561\n",
      "Epoch 5/100\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.6662 - accuracy: 0.5839 - val_loss: 0.6951 - val_accuracy: 0.5867\n",
      "Epoch 6/100\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.6611 - accuracy: 0.5911 - val_loss: 0.6999 - val_accuracy: 0.5357\n",
      "Epoch 7/100\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.6535 - accuracy: 0.6098 - val_loss: 0.7007 - val_accuracy: 0.5714\n",
      "Epoch 8/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.6455 - accuracy: 0.6126 - val_loss: 0.7010 - val_accuracy: 0.5510\n",
      "Epoch 9/100\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.6346 - accuracy: 0.6341 - val_loss: 0.7056 - val_accuracy: 0.5612\n",
      "Epoch 10/100\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.6252 - accuracy: 0.6428 - val_loss: 0.7019 - val_accuracy: 0.5765\n",
      "Epoch 11/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.6105 - accuracy: 0.6585 - val_loss: 0.7311 - val_accuracy: 0.5816\n",
      "Epoch 12/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.5985 - accuracy: 0.6729 - val_loss: 0.7285 - val_accuracy: 0.5969\n",
      "Epoch 13/100\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.5864 - accuracy: 0.6714 - val_loss: 0.7536 - val_accuracy: 0.5816\n",
      "Epoch 14/100\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.5764 - accuracy: 0.6858 - val_loss: 0.7400 - val_accuracy: 0.5663\n",
      "Epoch 15/100\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.5601 - accuracy: 0.6901 - val_loss: 0.7614 - val_accuracy: 0.6071\n",
      "Epoch 16/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.5438 - accuracy: 0.7159 - val_loss: 0.7823 - val_accuracy: 0.5612\n",
      "Epoch 17/100\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.5247 - accuracy: 0.7303 - val_loss: 0.7903 - val_accuracy: 0.6071\n",
      "Epoch 18/100\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.5101 - accuracy: 0.7461 - val_loss: 0.8155 - val_accuracy: 0.5408\n",
      "Epoch 19/100\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.4964 - accuracy: 0.7504 - val_loss: 0.8167 - val_accuracy: 0.5561\n",
      "Epoch 20/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.4926 - accuracy: 0.7504 - val_loss: 0.8571 - val_accuracy: 0.5561\n",
      "Epoch 21/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.4666 - accuracy: 0.7690 - val_loss: 0.8548 - val_accuracy: 0.5714\n",
      "Epoch 22/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.4477 - accuracy: 0.8020 - val_loss: 0.8903 - val_accuracy: 0.5612\n",
      "Epoch 23/100\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.4343 - accuracy: 0.8006 - val_loss: 0.9231 - val_accuracy: 0.5459\n",
      "Epoch 24/100\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.4222 - accuracy: 0.8106 - val_loss: 0.9018 - val_accuracy: 0.5561\n",
      "Epoch 25/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.4199 - accuracy: 0.8049 - val_loss: 0.9166 - val_accuracy: 0.5663\n",
      "iteration 17 – lstm_size:10, dropout:0, learning_rate:0.007525, epochs:15, loss:0.5601, accuracy:0.6901, val_loss:0.7614, val_accuracy:0.6071\n",
      "Epoch 1/100\n",
      "22/22 [==============================] - 3s 39ms/step - loss: 0.7002 - accuracy: 0.4892 - val_loss: 0.6891 - val_accuracy: 0.5561\n",
      "Epoch 2/100\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6881 - accuracy: 0.5380 - val_loss: 0.6879 - val_accuracy: 0.5153\n",
      "Epoch 3/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.6840 - accuracy: 0.5438 - val_loss: 0.6885 - val_accuracy: 0.5153\n",
      "Epoch 4/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.6811 - accuracy: 0.5839 - val_loss: 0.6892 - val_accuracy: 0.5153\n",
      "Epoch 5/100\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6756 - accuracy: 0.5753 - val_loss: 0.6878 - val_accuracy: 0.5306\n",
      "Epoch 6/100\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6717 - accuracy: 0.5768 - val_loss: 0.6882 - val_accuracy: 0.5510\n",
      "Epoch 7/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.6668 - accuracy: 0.5725 - val_loss: 0.6886 - val_accuracy: 0.5357\n",
      "Epoch 8/100\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.6617 - accuracy: 0.5854 - val_loss: 0.6888 - val_accuracy: 0.5306\n",
      "Epoch 9/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.6575 - accuracy: 0.5968 - val_loss: 0.6828 - val_accuracy: 0.5663\n",
      "Epoch 10/100\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6465 - accuracy: 0.6126 - val_loss: 0.6826 - val_accuracy: 0.5765\n",
      "Epoch 11/100\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6440 - accuracy: 0.6212 - val_loss: 0.6921 - val_accuracy: 0.5714\n",
      "Epoch 12/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.6352 - accuracy: 0.6327 - val_loss: 0.6812 - val_accuracy: 0.5816\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/100\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.6266 - accuracy: 0.6184 - val_loss: 0.6950 - val_accuracy: 0.5510\n",
      "Epoch 14/100\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6207 - accuracy: 0.6385 - val_loss: 0.6997 - val_accuracy: 0.5867\n",
      "Epoch 15/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.6125 - accuracy: 0.6413 - val_loss: 0.6903 - val_accuracy: 0.5765\n",
      "Epoch 16/100\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.5989 - accuracy: 0.6485 - val_loss: 0.7025 - val_accuracy: 0.5765\n",
      "Epoch 17/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.5822 - accuracy: 0.6714 - val_loss: 0.7262 - val_accuracy: 0.5612\n",
      "Epoch 18/100\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.5668 - accuracy: 0.6901 - val_loss: 0.7338 - val_accuracy: 0.5612\n",
      "Epoch 19/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.5481 - accuracy: 0.7274 - val_loss: 0.7575 - val_accuracy: 0.5714\n",
      "Epoch 20/100\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.5327 - accuracy: 0.7159 - val_loss: 0.7663 - val_accuracy: 0.5918\n",
      "Epoch 21/100\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.5123 - accuracy: 0.7561 - val_loss: 0.7963 - val_accuracy: 0.5867\n",
      "Epoch 22/100\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.4966 - accuracy: 0.7590 - val_loss: 0.8307 - val_accuracy: 0.5663\n",
      "Epoch 23/100\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.4777 - accuracy: 0.7877 - val_loss: 0.8382 - val_accuracy: 0.5459\n",
      "Epoch 24/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.4504 - accuracy: 0.7934 - val_loss: 0.8847 - val_accuracy: 0.5408\n",
      "Epoch 25/100\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.4192 - accuracy: 0.8164 - val_loss: 0.9379 - val_accuracy: 0.5408\n",
      "Epoch 26/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.3981 - accuracy: 0.8393 - val_loss: 0.9392 - val_accuracy: 0.5510\n",
      "Epoch 27/100\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.3724 - accuracy: 0.8407 - val_loss: 0.9699 - val_accuracy: 0.5612\n",
      "Epoch 28/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.3486 - accuracy: 0.8580 - val_loss: 1.0262 - val_accuracy: 0.5408\n",
      "Epoch 29/100\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.3183 - accuracy: 0.8709 - val_loss: 1.0859 - val_accuracy: 0.5459\n",
      "Epoch 30/100\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.2892 - accuracy: 0.9024 - val_loss: 1.1362 - val_accuracy: 0.5408\n",
      "Epoch 1/100\n",
      "22/22 [==============================] - 3s 41ms/step - loss: 0.6967 - accuracy: 0.5222 - val_loss: 0.6957 - val_accuracy: 0.4898\n",
      "Epoch 2/100\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6873 - accuracy: 0.5524 - val_loss: 0.6948 - val_accuracy: 0.5204\n",
      "Epoch 3/100\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6793 - accuracy: 0.5839 - val_loss: 0.6929 - val_accuracy: 0.5357\n",
      "Epoch 4/100\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6772 - accuracy: 0.5696 - val_loss: 0.6944 - val_accuracy: 0.5663\n",
      "Epoch 5/100\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.6720 - accuracy: 0.5925 - val_loss: 0.6878 - val_accuracy: 0.5561\n",
      "Epoch 6/100\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6559 - accuracy: 0.6055 - val_loss: 0.6988 - val_accuracy: 0.5612\n",
      "Epoch 7/100\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6420 - accuracy: 0.6169 - val_loss: 0.7158 - val_accuracy: 0.5510\n",
      "Epoch 8/100\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6264 - accuracy: 0.6413 - val_loss: 0.7215 - val_accuracy: 0.5714\n",
      "Epoch 9/100\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6033 - accuracy: 0.6528 - val_loss: 0.7265 - val_accuracy: 0.5255\n",
      "Epoch 10/100\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.5867 - accuracy: 0.6600 - val_loss: 0.7224 - val_accuracy: 0.5867\n",
      "Epoch 11/100\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.5536 - accuracy: 0.7174 - val_loss: 0.7252 - val_accuracy: 0.5612\n",
      "Epoch 12/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.5140 - accuracy: 0.7489 - val_loss: 0.8378 - val_accuracy: 0.5408\n",
      "Epoch 13/100\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.4731 - accuracy: 0.7633 - val_loss: 0.7544 - val_accuracy: 0.5663\n",
      "Epoch 14/100\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.4440 - accuracy: 0.8063 - val_loss: 0.8578 - val_accuracy: 0.5969\n",
      "Epoch 15/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.3904 - accuracy: 0.8321 - val_loss: 0.9575 - val_accuracy: 0.5561\n",
      "Epoch 16/100\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.3742 - accuracy: 0.8250 - val_loss: 0.9342 - val_accuracy: 0.5714\n",
      "Epoch 17/100\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.3081 - accuracy: 0.8824 - val_loss: 1.0794 - val_accuracy: 0.5612\n",
      "Epoch 18/100\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.2891 - accuracy: 0.8838 - val_loss: 1.0265 - val_accuracy: 0.5663\n",
      "Epoch 19/100\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.2483 - accuracy: 0.8996 - val_loss: 1.1487 - val_accuracy: 0.5714\n",
      "Epoch 20/100\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.2054 - accuracy: 0.9268 - val_loss: 1.1230 - val_accuracy: 0.5765\n",
      "Epoch 21/100\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.1725 - accuracy: 0.9426 - val_loss: 1.3049 - val_accuracy: 0.5459\n",
      "Epoch 22/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.1365 - accuracy: 0.9613 - val_loss: 1.2735 - val_accuracy: 0.5459\n",
      "Epoch 23/100\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.1132 - accuracy: 0.9641 - val_loss: 1.3590 - val_accuracy: 0.5357\n",
      "Epoch 24/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.1109 - accuracy: 0.9670 - val_loss: 1.4221 - val_accuracy: 0.5612\n",
      "Epoch 1/100\n",
      "22/22 [==============================] - 4s 43ms/step - loss: 0.6998 - accuracy: 0.5423 - val_loss: 0.6963 - val_accuracy: 0.4847\n",
      "Epoch 2/100\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6914 - accuracy: 0.5265 - val_loss: 0.6927 - val_accuracy: 0.5051\n",
      "Epoch 3/100\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6894 - accuracy: 0.5567 - val_loss: 0.6927 - val_accuracy: 0.5255\n",
      "Epoch 4/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.6865 - accuracy: 0.5681 - val_loss: 0.6917 - val_accuracy: 0.5357\n",
      "Epoch 5/100\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6846 - accuracy: 0.5524 - val_loss: 0.6933 - val_accuracy: 0.5255\n",
      "Epoch 6/100\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6746 - accuracy: 0.5725 - val_loss: 0.6984 - val_accuracy: 0.5204\n",
      "Epoch 7/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.6800 - accuracy: 0.5681 - val_loss: 0.6939 - val_accuracy: 0.5408\n",
      "Epoch 8/100\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6645 - accuracy: 0.5782 - val_loss: 0.6998 - val_accuracy: 0.5357\n",
      "Epoch 9/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.6703 - accuracy: 0.5940 - val_loss: 0.6982 - val_accuracy: 0.5459\n",
      "Epoch 10/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.6614 - accuracy: 0.5954 - val_loss: 0.7066 - val_accuracy: 0.5153\n",
      "Epoch 11/100\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.6666 - accuracy: 0.5968 - val_loss: 0.7016 - val_accuracy: 0.5510\n",
      "Epoch 12/100\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.6597 - accuracy: 0.6055 - val_loss: 0.7119 - val_accuracy: 0.5255\n",
      "Epoch 13/100\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6568 - accuracy: 0.6055 - val_loss: 0.7027 - val_accuracy: 0.5867\n",
      "Epoch 14/100\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6500 - accuracy: 0.6212 - val_loss: 0.7512 - val_accuracy: 0.5357\n",
      "Epoch 15/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.6499 - accuracy: 0.6126 - val_loss: 0.7156 - val_accuracy: 0.5408\n",
      "Epoch 16/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.6395 - accuracy: 0.6169 - val_loss: 0.7407 - val_accuracy: 0.5408\n",
      "Epoch 17/100\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6358 - accuracy: 0.6198 - val_loss: 0.7554 - val_accuracy: 0.5204\n",
      "Epoch 18/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.6356 - accuracy: 0.6255 - val_loss: 0.7567 - val_accuracy: 0.5459\n",
      "Epoch 19/100\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.6221 - accuracy: 0.6413 - val_loss: 0.7546 - val_accuracy: 0.5714\n",
      "Epoch 20/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.6117 - accuracy: 0.6628 - val_loss: 0.7949 - val_accuracy: 0.5561\n",
      "Epoch 21/100\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6155 - accuracy: 0.6227 - val_loss: 0.7889 - val_accuracy: 0.5663\n",
      "Epoch 22/100\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6051 - accuracy: 0.6628 - val_loss: 0.8127 - val_accuracy: 0.5459\n",
      "Epoch 23/100\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6002 - accuracy: 0.6514 - val_loss: 0.7930 - val_accuracy: 0.5357\n",
      "Epoch 1/100\n",
      "22/22 [==============================] - 4s 47ms/step - loss: 0.6945 - accuracy: 0.4935 - val_loss: 0.6969 - val_accuracy: 0.4796\n",
      "Epoch 2/100\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 0.6929 - accuracy: 0.4993 - val_loss: 0.6960 - val_accuracy: 0.4745\n",
      "Epoch 3/100\n",
      "22/22 [==============================] - 0s 13ms/step - loss: 0.6918 - accuracy: 0.5222 - val_loss: 0.6955 - val_accuracy: 0.4592\n",
      "Epoch 4/100\n",
      "22/22 [==============================] - 0s 13ms/step - loss: 0.6910 - accuracy: 0.5251 - val_loss: 0.6951 - val_accuracy: 0.4694\n",
      "Epoch 5/100\n",
      "22/22 [==============================] - 0s 17ms/step - loss: 0.6903 - accuracy: 0.5208 - val_loss: 0.6947 - val_accuracy: 0.4541\n",
      "Epoch 6/100\n",
      "22/22 [==============================] - 0s 16ms/step - loss: 0.6898 - accuracy: 0.5179 - val_loss: 0.6945 - val_accuracy: 0.4643\n",
      "Epoch 7/100\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6891 - accuracy: 0.5222 - val_loss: 0.6944 - val_accuracy: 0.4847\n",
      "Epoch 8/100\n",
      "22/22 [==============================] - 0s 13ms/step - loss: 0.6887 - accuracy: 0.5251 - val_loss: 0.6941 - val_accuracy: 0.4847\n",
      "Epoch 9/100\n",
      "22/22 [==============================] - 0s 16ms/step - loss: 0.6882 - accuracy: 0.5366 - val_loss: 0.6944 - val_accuracy: 0.4796\n",
      "Epoch 10/100\n",
      "22/22 [==============================] - 0s 14ms/step - loss: 0.6878 - accuracy: 0.5337 - val_loss: 0.6941 - val_accuracy: 0.4796\n",
      "Epoch 11/100\n",
      "22/22 [==============================] - 0s 14ms/step - loss: 0.6873 - accuracy: 0.5337 - val_loss: 0.6941 - val_accuracy: 0.4847\n",
      "Epoch 12/100\n",
      "22/22 [==============================] - 0s 17ms/step - loss: 0.6870 - accuracy: 0.5337 - val_loss: 0.6941 - val_accuracy: 0.4898\n",
      "Epoch 13/100\n",
      "22/22 [==============================] - 0s 13ms/step - loss: 0.6867 - accuracy: 0.5466 - val_loss: 0.6942 - val_accuracy: 0.4898\n",
      "Epoch 14/100\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 0.6861 - accuracy: 0.5466 - val_loss: 0.6941 - val_accuracy: 0.4949\n",
      "Epoch 15/100\n",
      "22/22 [==============================] - 0s 16ms/step - loss: 0.6858 - accuracy: 0.5567 - val_loss: 0.6941 - val_accuracy: 0.4898\n",
      "Epoch 16/100\n",
      "22/22 [==============================] - 0s 14ms/step - loss: 0.6854 - accuracy: 0.5581 - val_loss: 0.6941 - val_accuracy: 0.5051\n",
      "Epoch 17/100\n",
      "22/22 [==============================] - 0s 13ms/step - loss: 0.6850 - accuracy: 0.5595 - val_loss: 0.6942 - val_accuracy: 0.4949\n",
      "Epoch 18/100\n",
      "22/22 [==============================] - 0s 19ms/step - loss: 0.6847 - accuracy: 0.5610 - val_loss: 0.6944 - val_accuracy: 0.5051\n",
      "Epoch 19/100\n",
      "22/22 [==============================] - 0s 14ms/step - loss: 0.6843 - accuracy: 0.5638 - val_loss: 0.6944 - val_accuracy: 0.5000\n",
      "Epoch 20/100\n",
      "22/22 [==============================] - 0s 13ms/step - loss: 0.6839 - accuracy: 0.5739 - val_loss: 0.6943 - val_accuracy: 0.5051\n",
      "Epoch 21/100\n",
      "22/22 [==============================] - 0s 13ms/step - loss: 0.6836 - accuracy: 0.5681 - val_loss: 0.6945 - val_accuracy: 0.5000\n",
      "Epoch 22/100\n",
      "22/22 [==============================] - 0s 13ms/step - loss: 0.6833 - accuracy: 0.5825 - val_loss: 0.6944 - val_accuracy: 0.5000\n",
      "Epoch 23/100\n",
      "22/22 [==============================] - 0s 14ms/step - loss: 0.6828 - accuracy: 0.5839 - val_loss: 0.6945 - val_accuracy: 0.5000\n",
      "Epoch 24/100\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 0.6826 - accuracy: 0.5696 - val_loss: 0.6947 - val_accuracy: 0.5051\n",
      "Epoch 25/100\n",
      "22/22 [==============================] - 0s 14ms/step - loss: 0.6821 - accuracy: 0.5739 - val_loss: 0.6947 - val_accuracy: 0.5051\n",
      "Epoch 26/100\n",
      "22/22 [==============================] - 0s 17ms/step - loss: 0.6817 - accuracy: 0.5753 - val_loss: 0.6946 - val_accuracy: 0.5051\n",
      "Epoch 1/100\n",
      "22/22 [==============================] - 3s 38ms/step - loss: 0.7078 - accuracy: 0.4634 - val_loss: 0.7000 - val_accuracy: 0.4439\n",
      "Epoch 2/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.6972 - accuracy: 0.4821 - val_loss: 0.6948 - val_accuracy: 0.5459\n",
      "Epoch 3/100\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.6927 - accuracy: 0.5208 - val_loss: 0.6969 - val_accuracy: 0.5102\n",
      "Epoch 4/100\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.6887 - accuracy: 0.5323 - val_loss: 0.6934 - val_accuracy: 0.4847\n",
      "Epoch 5/100\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.6835 - accuracy: 0.5610 - val_loss: 0.6952 - val_accuracy: 0.4796\n",
      "Epoch 6/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.6807 - accuracy: 0.5595 - val_loss: 0.7014 - val_accuracy: 0.4847\n",
      "Epoch 7/100\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6723 - accuracy: 0.5839 - val_loss: 0.7059 - val_accuracy: 0.5102\n",
      "Epoch 8/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.6700 - accuracy: 0.5681 - val_loss: 0.7104 - val_accuracy: 0.5102\n",
      "Epoch 9/100\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.6552 - accuracy: 0.6112 - val_loss: 0.7201 - val_accuracy: 0.5051\n",
      "Epoch 10/100\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.6530 - accuracy: 0.5997 - val_loss: 0.7246 - val_accuracy: 0.4898\n",
      "Epoch 11/100\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.6494 - accuracy: 0.6083 - val_loss: 0.7126 - val_accuracy: 0.5153\n",
      "Epoch 12/100\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.6358 - accuracy: 0.6255 - val_loss: 0.7183 - val_accuracy: 0.5306\n",
      "Epoch 1/100\n",
      "22/22 [==============================] - 3s 35ms/step - loss: 0.7021 - accuracy: 0.4706 - val_loss: 0.6886 - val_accuracy: 0.5459\n",
      "Epoch 2/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.6888 - accuracy: 0.5452 - val_loss: 0.6897 - val_accuracy: 0.5459\n",
      "Epoch 3/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.6842 - accuracy: 0.5768 - val_loss: 0.6940 - val_accuracy: 0.5306\n",
      "Epoch 4/100\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6771 - accuracy: 0.5638 - val_loss: 0.6945 - val_accuracy: 0.5357\n",
      "Epoch 5/100\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6739 - accuracy: 0.5667 - val_loss: 0.6981 - val_accuracy: 0.5306\n",
      "Epoch 6/100\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.6705 - accuracy: 0.5768 - val_loss: 0.6889 - val_accuracy: 0.5459\n",
      "Epoch 7/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.6621 - accuracy: 0.5983 - val_loss: 0.7008 - val_accuracy: 0.5408\n",
      "Epoch 8/100\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.6546 - accuracy: 0.6141 - val_loss: 0.6999 - val_accuracy: 0.5459\n",
      "Epoch 9/100\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6442 - accuracy: 0.6184 - val_loss: 0.7019 - val_accuracy: 0.5714\n",
      "Epoch 10/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.6363 - accuracy: 0.6356 - val_loss: 0.7148 - val_accuracy: 0.5459\n",
      "Epoch 11/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.6225 - accuracy: 0.6428 - val_loss: 0.7232 - val_accuracy: 0.5612\n",
      "Epoch 12/100\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6143 - accuracy: 0.6499 - val_loss: 0.7502 - val_accuracy: 0.5714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.5851 - accuracy: 0.6930 - val_loss: 0.7587 - val_accuracy: 0.5663\n",
      "Epoch 14/100\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.5713 - accuracy: 0.7102 - val_loss: 0.7876 - val_accuracy: 0.5765\n",
      "Epoch 15/100\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.5473 - accuracy: 0.7159 - val_loss: 0.7887 - val_accuracy: 0.5816\n",
      "Epoch 16/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.5369 - accuracy: 0.7317 - val_loss: 0.8085 - val_accuracy: 0.5867\n",
      "Epoch 17/100\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.5041 - accuracy: 0.7633 - val_loss: 0.8789 - val_accuracy: 0.5663\n",
      "Epoch 18/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.4739 - accuracy: 0.7719 - val_loss: 0.8994 - val_accuracy: 0.5612\n",
      "Epoch 19/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.4316 - accuracy: 0.8106 - val_loss: 0.9423 - val_accuracy: 0.5561\n",
      "Epoch 20/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.4068 - accuracy: 0.8221 - val_loss: 0.9991 - val_accuracy: 0.5408\n",
      "Epoch 21/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.4171 - accuracy: 0.8034 - val_loss: 0.9825 - val_accuracy: 0.5918\n",
      "Epoch 22/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.3790 - accuracy: 0.8207 - val_loss: 1.0295 - val_accuracy: 0.5459\n",
      "Epoch 23/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.3179 - accuracy: 0.8838 - val_loss: 1.0370 - val_accuracy: 0.5714\n",
      "Epoch 24/100\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.2703 - accuracy: 0.8981 - val_loss: 1.2099 - val_accuracy: 0.5561\n",
      "Epoch 25/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.2760 - accuracy: 0.8938 - val_loss: 1.2374 - val_accuracy: 0.5765\n",
      "Epoch 26/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.2823 - accuracy: 0.8694 - val_loss: 1.1508 - val_accuracy: 0.5867\n",
      "Epoch 27/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.2185 - accuracy: 0.9139 - val_loss: 1.2933 - val_accuracy: 0.5612\n",
      "Epoch 28/100\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.1917 - accuracy: 0.9283 - val_loss: 1.3163 - val_accuracy: 0.5714\n",
      "Epoch 29/100\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.1862 - accuracy: 0.9340 - val_loss: 1.3957 - val_accuracy: 0.5765\n",
      "Epoch 30/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.1542 - accuracy: 0.9354 - val_loss: 1.4315 - val_accuracy: 0.5459\n",
      "Epoch 31/100\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.1304 - accuracy: 0.9527 - val_loss: 1.4914 - val_accuracy: 0.5663\n",
      "Epoch 1/100\n",
      "22/22 [==============================] - 3s 39ms/step - loss: 0.7017 - accuracy: 0.5093 - val_loss: 0.6906 - val_accuracy: 0.5051\n",
      "Epoch 2/100\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.6929 - accuracy: 0.5251 - val_loss: 0.6931 - val_accuracy: 0.5204\n",
      "Epoch 3/100\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.6889 - accuracy: 0.5595 - val_loss: 0.6944 - val_accuracy: 0.5000\n",
      "Epoch 4/100\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.6836 - accuracy: 0.5710 - val_loss: 0.6939 - val_accuracy: 0.5408\n",
      "Epoch 5/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.6816 - accuracy: 0.5610 - val_loss: 0.6842 - val_accuracy: 0.5357\n",
      "Epoch 6/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.6726 - accuracy: 0.5811 - val_loss: 0.6913 - val_accuracy: 0.5459\n",
      "Epoch 7/100\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.6715 - accuracy: 0.5796 - val_loss: 0.7098 - val_accuracy: 0.5255\n",
      "Epoch 8/100\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6615 - accuracy: 0.6011 - val_loss: 0.7074 - val_accuracy: 0.5561\n",
      "Epoch 9/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.6594 - accuracy: 0.6155 - val_loss: 0.6889 - val_accuracy: 0.5510\n",
      "Epoch 10/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.6536 - accuracy: 0.6169 - val_loss: 0.7122 - val_accuracy: 0.5510\n",
      "Epoch 11/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.6373 - accuracy: 0.6485 - val_loss: 0.7257 - val_accuracy: 0.5459\n",
      "Epoch 12/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.6369 - accuracy: 0.6356 - val_loss: 0.7150 - val_accuracy: 0.5561\n",
      "Epoch 13/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.6069 - accuracy: 0.6671 - val_loss: 0.7923 - val_accuracy: 0.5204\n",
      "Epoch 14/100\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.5897 - accuracy: 0.6829 - val_loss: 0.8129 - val_accuracy: 0.5255\n",
      "Epoch 15/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.5744 - accuracy: 0.6930 - val_loss: 0.7747 - val_accuracy: 0.5306\n",
      "Epoch 16/100\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.5431 - accuracy: 0.7331 - val_loss: 0.8411 - val_accuracy: 0.5459\n",
      "Epoch 17/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.5157 - accuracy: 0.7461 - val_loss: 0.8929 - val_accuracy: 0.5357\n",
      "Epoch 18/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.4900 - accuracy: 0.7475 - val_loss: 0.9109 - val_accuracy: 0.5561\n",
      "Epoch 1/100\n",
      "22/22 [==============================] - 4s 37ms/step - loss: 0.7020 - accuracy: 0.4921 - val_loss: 0.6889 - val_accuracy: 0.5255\n",
      "Epoch 2/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.6973 - accuracy: 0.5251 - val_loss: 0.6897 - val_accuracy: 0.5306\n",
      "Epoch 3/100\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.6825 - accuracy: 0.5552 - val_loss: 0.6913 - val_accuracy: 0.5357\n",
      "Epoch 4/100\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.6884 - accuracy: 0.5466 - val_loss: 0.6897 - val_accuracy: 0.5204\n",
      "Epoch 5/100\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.6804 - accuracy: 0.5710 - val_loss: 0.6906 - val_accuracy: 0.5459\n",
      "Epoch 6/100\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.6787 - accuracy: 0.5653 - val_loss: 0.6950 - val_accuracy: 0.5102\n",
      "Epoch 7/100\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.6795 - accuracy: 0.5710 - val_loss: 0.6920 - val_accuracy: 0.5510\n",
      "Epoch 8/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.6765 - accuracy: 0.5710 - val_loss: 0.6913 - val_accuracy: 0.5204\n",
      "Epoch 9/100\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.6813 - accuracy: 0.5725 - val_loss: 0.6919 - val_accuracy: 0.5306\n",
      "Epoch 10/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.6759 - accuracy: 0.5495 - val_loss: 0.6935 - val_accuracy: 0.5510\n",
      "Epoch 11/100\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.6682 - accuracy: 0.5839 - val_loss: 0.6979 - val_accuracy: 0.5000\n",
      "Epoch 12/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.6576 - accuracy: 0.6055 - val_loss: 0.7022 - val_accuracy: 0.5357\n",
      "Epoch 13/100\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.6676 - accuracy: 0.5954 - val_loss: 0.7125 - val_accuracy: 0.5153\n",
      "Epoch 14/100\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.6518 - accuracy: 0.6212 - val_loss: 0.7070 - val_accuracy: 0.5000\n",
      "Epoch 15/100\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.6565 - accuracy: 0.5983 - val_loss: 0.7087 - val_accuracy: 0.5102\n",
      "Epoch 16/100\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.6527 - accuracy: 0.6313 - val_loss: 0.7113 - val_accuracy: 0.5510\n",
      "Epoch 17/100\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.6504 - accuracy: 0.6011 - val_loss: 0.7034 - val_accuracy: 0.5306\n"
     ]
    }
   ],
   "source": [
    "results, best_model, history = random_search(model_fn, search_space, iterations, 'search_new')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd83fd2",
   "metadata": {},
   "source": [
    "After training a model, Keras reports two main loss values:\n",
    "\n",
    "Training Loss: Loss calculated on the training dataset.\n",
    "Validation Loss: Loss calculated on a separate validation dataset to monitor how well the model generalizes to unseen data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6b3d902a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lstm_size</th>\n",
       "      <th>dropout</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>epochs</th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.007525</td>\n",
       "      <td>15</td>\n",
       "      <td>0.560085</td>\n",
       "      <td>0.690100</td>\n",
       "      <td>0.761428</td>\n",
       "      <td>0.607143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.007525</td>\n",
       "      <td>20</td>\n",
       "      <td>0.515388</td>\n",
       "      <td>0.754663</td>\n",
       "      <td>0.777109</td>\n",
       "      <td>0.596939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.005050</td>\n",
       "      <td>16</td>\n",
       "      <td>0.576070</td>\n",
       "      <td>0.684362</td>\n",
       "      <td>0.799873</td>\n",
       "      <td>0.591837</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   lstm_size  dropout  learning_rate  epochs      loss  accuracy  val_loss  \\\n",
       "2         10     0.00       0.007525      15  0.560085  0.690100  0.761428   \n",
       "1         10     0.00       0.007525      20  0.515388  0.754663  0.777109   \n",
       "0         45     0.45       0.005050      16  0.576070  0.684362  0.799873   \n",
       "\n",
       "   val_accuracy  \n",
       "2      0.607143  \n",
       "1      0.596939  \n",
       "0      0.591837  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.sort_values('val_accuracy', ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16838bd",
   "metadata": {},
   "source": [
    "According to the above results, the best model has the following parameters: LSTM size is 10, dropout is 0.00 and learning rate is 0.007525. This model provides validation accuracy of approximately 0.61.\n",
    "\n",
    "A validation loss of 0.761428 indicates the average error between the predicted and actual class probabilities on the validation set at a specific point in training. Lower values indicate better performance, but the value itself doesn’t directly represent accuracy; rather, it measures the “fit” of predicted probabilities.\n",
    "\n",
    "In general, a low validation loss means the model’s predictions closely match the actual labels for the validation set.\n",
    "A high validation loss may imply poor generalization, which could result from underfitting (model not learning enough) or overfitting (model too specialized to the training data and not performing well on new data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "198bcfc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-73-190b66066499>:1: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n",
      "  best_model.evaluate_generator(test_generator)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7736585736274719, 0.5102040767669678]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.evaluate_generator(test_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42185039",
   "metadata": {},
   "source": [
    "When applied to the test set of data, the accuracy is approximately 0.51 whereas the loss is 0.774."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f362b58f",
   "metadata": {},
   "source": [
    "## Step 5. Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "01e35634",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history['accuracy'])\n",
    "plt.plot(history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d24aa92",
   "metadata": {},
   "source": [
    "As can be seen from the graph - the model still tends to overfit. This figure shows that the train accuracy increases with number of epochs, while the validation accuracy just keeps flactuating. This indicates that model is unable to generalise on unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2994c7",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
